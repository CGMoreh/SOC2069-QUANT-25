[
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w5.html",
    "href": "Materials/Worksheets/draft_worksheet_w5.html",
    "title": "Workshop 5 Worksheet",
    "section": "",
    "text": "By the end of the session, you should be familiar with:\n\nrecoding/dichotomising categorical variables in JASP\ninterpreting inferential statistics in regression outputs\nunderstanding and describing the uncertainty around statistical results\n\n\n\n\nIn this worksheet we will revisit the linear and logistic regression models created in the previous two workshops and we will reassess those results by focusing on the uncertainty around the estimated coefficients and the meaning behind them. You will practice fitting regression models to address your assignment question of choice, and in the process we learn some further data transformation procedures in JASP.\n\n\n\n\n\nIn Exercise 3 on Worksheet 3 you fit a regression model of social trust as a function of inequality and Region using the trust_inequality.dta dataset. In this exercise, refit that multiple linear regression model, but in addition to what you have done in Workshop 4, also request Confidence intervals (95%) to be included in the output summary table:\n\n\n\n\n\nThe output Coefficients table should look something like this:\n\n\n\n\n\n\nQuestions\n\nUsing the lecture slides and the assigned readings, interpret the results focusing on the meaning of the “Standard Error”, “95% CI” and “p” columns\n\n\n\n\n\nIn Exercise 5.1 - Task 5.1.4 (Worksheet 4) you fit a binary logistic regression model of social trust as a function of inequality and Region using as dependent variable a dichotomised version of the trust_pct variable (trust_d) from the trust_inequality dataset. In this exercise, refit that multiple binary logistic regression model, but in addition to what you have done in Workshop 5, also request Confidence intervals (95%) to be included in the output summary table:\n\n\n\n\n\nThe output Coefficients table should look something like this:\n\n\n\n\n\n\nQuestions\n\nUsing the lecture slides and the assigned readings, interpret the results focusing on the meaning of the “Standard Error”, “95% Confidence Interval” and “p” columns\nDo the coefficients - particularly as viewed through the confidence intervals - on the Region variable(s) seem plausible? What do you think might be causing the very large “effects” and highly uncertain effects?\n\nTip: You may want to check a simple cross-tabulation (contingency table) of trust_d by Region to develop some intuition in answering the second point above.\n\n\n\n\n\nIn In Exercise 5.1 - Task 5.1.1 (Worksheet 4) we dichotomised the trust_pct numeric scale-type variable by cutting the scale in two around its mean value. In practical data analysis you will often encounter situations when you will want to recode categorical variables into fewer categories than the original scale. Such a situation may emerge in the course of an assignment task in which the variable chosen as dependent variable in a planned regression model is multi-categorical (multinomial). There are special statistical models for such dependent variables, however, in this module we are not covering these more advanced methods. Instead, you will want to transform the variables - if logically, conceptually or theoretically possible - into binary/binomial/dichotomous variables (i.e. variables with only two categories).\nSuch transformations are easy to implement in JASP, and the procedure amounts to manually recoding the values of the categories by giving several categories the same values.\nIn this exercise, you can use the data_transformation dataset available to download from the module website’s Data page to replicate the transformations shown in the two videos below. The downloaded dataset is in .jasp format and can be opened directly in the software by double-clicking on the downloaded file.\nThe procedure for transforming categorical variables is demonstrated in the following YouTube videos:\n\n\n\n\n\nYou will find a detailed guide for Assignment 1 on Canvas. The guide contains detailed advice on all the steps involved in completing the assignment, including on the structure of the final report. In this exercise, you will focus on the analysis component of the assignment which you can then expand or change if your literature review and interpretation of the results necessitate it.\nOnce you have chosen your preferred research question from among the listed ones and identified the dataset and variables you will want to use to address the question, the guidance advises the following steps for your analysis:\n\ndescribe the source of the (original) data\nexplain the motivation behind the variables you have chosen\ndescribe your chosen variables using summary descriptive statistics, visual plots and/or frequency tables, as best suited for the given variable type\nvisualise or cross-tabulate the simple bi-variate association between your two main variables (i.e. the dependent and main independent variable that relate to the main concepts underpinning the chosen research question; e.g. “trust in the police” and “victimisation” in the case of question E)\ntransform/clean up your variables for statistical analysis if needed (e.g. dichotomise a categorical dependent variable to make it usable in a logistic regression; remove redundant categories or set them as missing values; reorder variable levels; etc)\ntest the association statistically using a simple bi-variate regression model (linear or logistic, as required by your dependent variable) and interpret the results\nexpand the simple regression model into a multiple regression by adding a small selection of control variables - making sure to explain your choices behind the included variables in step 1 above, and ideally tie your choices to existing literature on the topic of your research question - and interpret these results\n\nYou will perform these analysis steps in JASP, following which you will:\n\nwrite down your interpretation of your results in as much detail as possible (either (or both) In JASP notes and your main Word/Text editor document that you are using to write the main text of the report in; it’s a good idea to start saving your notes and interpretations alongside the analysis and outputs directly in JASP to make your work reproducible, then copy it over and adapt it in your main document;\nSelect which outputs (descriptive tables, graphs, statistical output tables) you will want to include in the main text of your report and copy them over from JASP into your Word document/text editor. To copy and paste outputs from JASP, you can click on the small black down-arrows next to the output and select “Copy”, then paste it into your text editor. (Keep in mind that tables will require some manual improvements in Word/text editor to make the content fit the page well).\n\n\n\n\n\n\n\nMake sure to give a caption/title to your graphs and tables in your report."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w5.html#learning-outcomes",
    "href": "Materials/Worksheets/draft_worksheet_w5.html#learning-outcomes",
    "title": "Workshop 5 Worksheet",
    "section": "",
    "text": "By the end of the session, you should be familiar with:\n\nrecoding/dichotomising categorical variables in JASP\ninterpreting inferential statistics in regression outputs\nunderstanding and describing the uncertainty around statistical results"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w5.html#intro",
    "href": "Materials/Worksheets/draft_worksheet_w5.html#intro",
    "title": "Workshop 5 Worksheet",
    "section": "",
    "text": "In this worksheet we will revisit the linear and logistic regression models created in the previous two workshops and we will reassess those results by focusing on the uncertainty around the estimated coefficients and the meaning behind them. You will practice fitting regression models to address your assignment question of choice, and in the process we learn some further data transformation procedures in JASP."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w5.html#exercise-6.1-return-to-modelling-social-trust-at-national-level-as-a-function-of-inequality-and-region",
    "href": "Materials/Worksheets/draft_worksheet_w5.html#exercise-6.1-return-to-modelling-social-trust-at-national-level-as-a-function-of-inequality-and-region",
    "title": "Workshop 5 Worksheet",
    "section": "",
    "text": "In Exercise 3 on Worksheet 3 you fit a regression model of social trust as a function of inequality and Region using the trust_inequality.dta dataset. In this exercise, refit that multiple linear regression model, but in addition to what you have done in Workshop 4, also request Confidence intervals (95%) to be included in the output summary table:\n\n\n\n\n\nThe output Coefficients table should look something like this:\n\n\n\n\n\n\nQuestions\n\nUsing the lecture slides and the assigned readings, interpret the results focusing on the meaning of the “Standard Error”, “95% CI” and “p” columns\n\n\n\n\n\nIn Exercise 5.1 - Task 5.1.4 (Worksheet 4) you fit a binary logistic regression model of social trust as a function of inequality and Region using as dependent variable a dichotomised version of the trust_pct variable (trust_d) from the trust_inequality dataset. In this exercise, refit that multiple binary logistic regression model, but in addition to what you have done in Workshop 5, also request Confidence intervals (95%) to be included in the output summary table:\n\n\n\n\n\nThe output Coefficients table should look something like this:\n\n\n\n\n\n\nQuestions\n\nUsing the lecture slides and the assigned readings, interpret the results focusing on the meaning of the “Standard Error”, “95% Confidence Interval” and “p” columns\nDo the coefficients - particularly as viewed through the confidence intervals - on the Region variable(s) seem plausible? What do you think might be causing the very large “effects” and highly uncertain effects?\n\nTip: You may want to check a simple cross-tabulation (contingency table) of trust_d by Region to develop some intuition in answering the second point above."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w5.html#exercise-6.2.-recoding-categorical-variables",
    "href": "Materials/Worksheets/draft_worksheet_w5.html#exercise-6.2.-recoding-categorical-variables",
    "title": "Workshop 5 Worksheet",
    "section": "",
    "text": "In In Exercise 5.1 - Task 5.1.1 (Worksheet 4) we dichotomised the trust_pct numeric scale-type variable by cutting the scale in two around its mean value. In practical data analysis you will often encounter situations when you will want to recode categorical variables into fewer categories than the original scale. Such a situation may emerge in the course of an assignment task in which the variable chosen as dependent variable in a planned regression model is multi-categorical (multinomial). There are special statistical models for such dependent variables, however, in this module we are not covering these more advanced methods. Instead, you will want to transform the variables - if logically, conceptually or theoretically possible - into binary/binomial/dichotomous variables (i.e. variables with only two categories).\nSuch transformations are easy to implement in JASP, and the procedure amounts to manually recoding the values of the categories by giving several categories the same values.\nIn this exercise, you can use the data_transformation dataset available to download from the module website’s Data page to replicate the transformations shown in the two videos below. The downloaded dataset is in .jasp format and can be opened directly in the software by double-clicking on the downloaded file.\nThe procedure for transforming categorical variables is demonstrated in the following YouTube videos:"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w5.html#exercise-6.3.-assignment-1-analysis",
    "href": "Materials/Worksheets/draft_worksheet_w5.html#exercise-6.3.-assignment-1-analysis",
    "title": "Workshop 5 Worksheet",
    "section": "",
    "text": "You will find a detailed guide for Assignment 1 on Canvas. The guide contains detailed advice on all the steps involved in completing the assignment, including on the structure of the final report. In this exercise, you will focus on the analysis component of the assignment which you can then expand or change if your literature review and interpretation of the results necessitate it.\nOnce you have chosen your preferred research question from among the listed ones and identified the dataset and variables you will want to use to address the question, the guidance advises the following steps for your analysis:\n\ndescribe the source of the (original) data\nexplain the motivation behind the variables you have chosen\ndescribe your chosen variables using summary descriptive statistics, visual plots and/or frequency tables, as best suited for the given variable type\nvisualise or cross-tabulate the simple bi-variate association between your two main variables (i.e. the dependent and main independent variable that relate to the main concepts underpinning the chosen research question; e.g. “trust in the police” and “victimisation” in the case of question E)\ntransform/clean up your variables for statistical analysis if needed (e.g. dichotomise a categorical dependent variable to make it usable in a logistic regression; remove redundant categories or set them as missing values; reorder variable levels; etc)\ntest the association statistically using a simple bi-variate regression model (linear or logistic, as required by your dependent variable) and interpret the results\nexpand the simple regression model into a multiple regression by adding a small selection of control variables - making sure to explain your choices behind the included variables in step 1 above, and ideally tie your choices to existing literature on the topic of your research question - and interpret these results\n\nYou will perform these analysis steps in JASP, following which you will:\n\nwrite down your interpretation of your results in as much detail as possible (either (or both) In JASP notes and your main Word/Text editor document that you are using to write the main text of the report in; it’s a good idea to start saving your notes and interpretations alongside the analysis and outputs directly in JASP to make your work reproducible, then copy it over and adapt it in your main document;\nSelect which outputs (descriptive tables, graphs, statistical output tables) you will want to include in the main text of your report and copy them over from JASP into your Word document/text editor. To copy and paste outputs from JASP, you can click on the small black down-arrows next to the output and select “Copy”, then paste it into your text editor. (Keep in mind that tables will require some manual improvements in Word/text editor to make the content fit the page well).\n\n\n\n\n\n\n\nMake sure to give a caption/title to your graphs and tables in your report."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w3.html",
    "href": "Materials/Worksheets/draft_worksheet_w3.html",
    "title": "Workshop 3 Worksheet",
    "section": "",
    "text": "By the end of the session, you should be familiar with:\n\nrunning simple and multiple linear regression in JASP\nperforming a correlation analysis in JASP\nmodel building in JASP\nthe interpretation of linear regression coefficients\n\n\n\n\nWe continue where we left off in the last Workshop, taking further Workshop 2 Worksheet - Exercise 2 in which we made a scatter plot of inequality by social trust using the Trust & Inequality (trust_inequality.dta) dataset, which can be downloaded from https://cgmoreh.github.io/SOC2069-QUANT/Data/.\nIn that exercise we simplified the default output by removing the univariate distributions of the variables displayed on the margins and the regression line cutting through the plot. Now, however, we will focus on understanding what that “regression line” is actually telling us.\n\n\n\n\n\n\nSolutions\n\n\n\nA JASP file with the solutions to the exercises can be downloaded from HERE.\n\n\n\n\n\n\nIf you haven’t yet downloaded it in the last workshop, download the Trust & Inequality (trust_inequality.dta) dataset from https://cgmoreh.github.io/SOC2069-QUANT/Data/\n\n\nAs a first step, create a scatter plot visualising the “relationship” (co-variation, joint distribution, …) between social trust (trust_pct) and inequality (inequality_s80s20). This is Exercise 2 from Workshop 2 - if you need a reminder of how to do it, check Workshop 2 Worksheet - Exercise 2 or your saved .jasp file containing your workshop analysis from Workshop 2.\n\n\n\nNow let’s dig deeper into the meaning of the regression line by building a simple bivariate linear regression model of social trust as a function of societal inequality (i.e. a model aiming to explain/predict values of social trust in various countries depending on the value of societal inequality in those countries).\nTo build a linear regression model in JASP, click through the Menu tabs:\n\\[ \\text{Regression} \\longrightarrow \\text{[Classical] Linear regression} \\] In the Linear regression panel, move the “social trust” variable to the \\(\\text{Dependent Variable}\\) box and the “inequality” variable to the \\(\\text{Covariates}\\) box.\nThe results from the linear regression model will appear in the outputs window on the right.\n\n\n\n\n\n\nSolution\n\n\n\nThe output should look something like this:\n\n\n\n\n\n\n\n\n\n\nIn general terms, the coefficient of interest (the one associated with the independent variable) tells us: that a one-unit difference/change on the independent variable scale is associated with a difference/change in the dependent variable of the size shown by the value of the coefficient.\nBut what does this mean substantively in the context of our two variables?\n\nQuestions\n\nUsing the lecture slides and Chapter 7 (“Linear regression with a single predictor”) from the Introduction to Modern Statistics (IMS), interpret the meaning of the regression coefficient on “inequality”.\nAdd a note on the JASP output under the \\(\\text{Coefficients}\\) output and write down your interpretation there. [Tip: You’ve already practiced adding notes to the outputs in Workshop 1, Exercise 3, Point 7]\nWhere can you find the coefficient of correlation (\\(R\\)) in the outputs? What about the coefficient of determination (\\(R^2\\))?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThe tables in the outputs list results from two “models”. One is a model without any explanatory (independent/predictor) variables (M0), in which case the (Intercept) value is nothing else then the average (mean) value of the outcome (dependent/explained) variable calculated on the sample of cases/observations (i.e. countries here) that were included in the model (i.e. only those who had a valid measurement on both of the variables, so a non-missing value for both the “trust” and the “inequity” variable). This “null model” is given to us by JASP by default, without us asking for it. The model we actually fit is presented as M1, and this is what we are interested in. As we see in the Coefficients table, the coefficient associated with the (Intercept) value in M1 is no longer the mean/average level of trust_pct, but instead 45.384. This value represents the expected score on the dependent variable (trust_pct) when the value of the independent variable (inequality_s80s20) is 0. As it will become apparent from the discussion below, a value of 0 for the inequality_s80s20 variable is highly unrealistic, and this is often the case. However, that’s not a problem, because the (Intercept) value is meant to provide a mathematical baseline to the model and we generally are not interested in interpreting it., so we won’t. What we are interested in is the coefficient on our independent (explanatory/predictor) variable.\nWhat is the meaning of the regression coefficient on “inequality”?\nIn general terms, the coefficient of interest (the one associated with the independent variable) tells us: that a one-unit difference/change on the independent variable scale is associated with a difference/change in the dependent variable of the size shown by the value of the coefficient.\nBut what does this mean substantively in the context of our two variables?\nFrom the Coefficients table we see that the regression coefficient associated with our predictor/independent variable is -3.114. This tells us that a one-unit increase on the “inequality” scale is associated with a -3.114-unit change on the “trust” scale. To give this a more meaningful interpretation, we need to know what exactly a unit change means on each scale, and for that we need to know what our variables measure.\nUnderstanding the “trust” measurement (the trust_pct variable) is more straightforward. We know that it measures the percentage of respondents in each country who answered that “in general, most people can be trusted” to the standard social trust survey question in the World Values Survey. A unit on that scale is therefore one percentage-point.\nUnderstanding the “inequality” scale is much trickier, because that scale measures a ratio. Specifically, it denotes the so-called income quintile share ratio, a commonly employed measurement of inequality in the income distribution in a country. It is calculated as the ratio of total income received by the 20% of the population with the highest income (the top quintile) to that received by the 20% of the population with the lowest income (the bottom quintile) [By the way, a “quintile” (from the Latin word “quintus” for “five”) is simply a value that divides a scale into five equal parts - e.g. a scale of all the integers between 0 and 100 divided into five equal parts will contain 20 integers in each part, i.e. 100÷5]. In our dataset, the variable measuring it - inequality_s80s20 - was calculated by taking the ratio of (i.e. dividing) the variables income_top20 and income_bottom20. For example, looking at the first entry, for Albania, we see that income_top20 = 39.6375 and income_bottom20 = 7.9125, so inequality_s80s20 will be 39.6÷7.9 = 5.009478673 (or 5.01 rounded up to two decimal points).\nThat’s fairly easy to get our heads around, but because its unit of measurement is a ratio it also makes it more difficult to compare one value to another. The best way of approaching it is through some logical examples. Say, for instance, that we want to posit the existence of a perfectly equal society (in terms of income distribution, at least). What would that entail? It would entail that the top-20% earners and the bottom-20% earners own the same share of the total available income. For example, if the top-20% possess 20% of the income distribution and the bottom-20% also possess 20% of the income distribution (with the remaining 60% of income possessed by the middle-60% of earners), then the inequality ratio would be 20÷20=1. The ratio is the same if the “middle-class” is very thin and both the top- and the bottom-20% of earners possess, say, 42% of the income distribution (84% in total): 42÷42=1. To generalise, when two values are equal, their ratio is 1. But what happens if we hypothesise a very unequal society, say one in which the top-20% of the earners share 90% of all income distributed within an economy, while the bottom-20% share on only 0.5% of the income distribution? In such a scenario, the inequality ratio would be 90÷0.5=180; and, in theory, the value of this ratio can be limitlessly high (e.g. 99.999÷0.00005=1,999,980; yes, that is indeed almost 2 million!). The larger the gap, the more extreme the ratio value, and the change between values is not “linear”.\nHowever, the above scenarios are empirically unrealistic. In fact, if we look at our actual data, the lowest share of the income scale possessed by the top-20% in any country is 34.56 (Slovakia), while the highest share is 57.3 (Brazil). For income possessed by the bottom-20%, the lowest percentage is 3.45 (Brazil) and the highest value is 10.08 (Ukraine). In terms of inequality_s80s20, we then see the lowest value at 3.52 (Ukraine) and the highest at 16.64 (Brazil). On this more restricted empirical scale (running from 3.52 to 16.64), the difference between the values is more equal, making the changes from one value to another approximately linear.\nSo, then, what does a one-unit change on this “empirical” scale mean? It means, for example, the difference between an inequality score of 30÷10=3 and one of 24÷6=4; or, approximately, between 40÷7.9=5.06 (Lebanon) and 42.83÷7.08=6.05 (Nigeria). It is, in other words, a rather large unit; the entire scale (running from 3.52 to 16.64) contains just over 13 such units (16.64 - 3.52 = 13.12). By contrast, a percentage scale contains 100 units of 1%-point each. Due to such differences in the scales that are being compared, it is very common to “standardise” the variables used in a regression so that each unit involved is “equal”. On the other hand, the difficulty is then shifted onto interpreting those standardized coefficients on the original meaningful scale of the variables involved. In other words, it’s a challenge either way. In this exercise, we have left the two variables involved in the regression unstandardised, so a “unit” has a different meaning in the case of each variable.\nNow, having thought deeply about what the variables involved actually measure, we can interpret the regression coefficient, which is telling us that our simple model predicts that a country with an inequality score 1 points higher than that of another country will have, on average, a trust score 3.114% lower than that other country. If we look, for example, at the trust scores of Lebanon and Nigeria, we can get a sense of how well our model does at predicting this specific case: 12.68% - 9.92% = 2.76%. It’s not a perfect prediction, but it’s a much better one than we could have made had we not had any information on “inequality”. Ultimately, our model helps us make a better informed assessment of the variability in trust across countries, even if it will either overestimate or underestimate any given actual value.\nWhere can you find the coefficient of correlation (\\(R\\)) in the outputs?\nThe idea behind the coefficient of correlation (\\(R\\)) relates somewhat to the discussion above regarding “standardisation”. In fact, the correlation coefficient is calculated by standardising the scales of the two variables involved (trust_pct and inequality_s80s20) and expressing the coefficient on that standardised scale. In our JASP output, we can find this information under the Standardized column in the Coefficients table, and as an absolute value (i.e. non-negative) is shown under the R column in the Model Summary table.\nBut what exactly does “standardisation” mean?\nOne of the most commonly employed “standard scores” is the z-score, which tells us how many “standard deviations” (SD) each score/value is from the mean/average score/value on a given measurement scale. The ﻿\\(z\\)-score for a value \\(x\\)﻿ is calculated as \\(z_x={(x-\\mu_X)\\over\\sigma_X}\\) ﻿, where \\(x\\)﻿ is any single value on a scale \\(X\\), \\(\\mu_X\\) is the mean/average of \\(X\\) and \\(\\sigma_X\\) is the standard deviation of \\(X\\). In JASP, we can use the zScores() drag-and-drop function to calculate this. If we were to create two new variables that are the z-standardised versions of the trust_pct and inequality_s80s20 variables, respectively, and we ran the same regression as above on those variables, then the obtained regression coefficient on “standardised inequality” would have coincided with the correlation coefficient and it would have been -0.430.1 On these newly standardized scales, a value of 1 means “one standard deviation above the mean”, a value of 2 means “two standard deviations above the mean”, a value of -1 means “one standard deviation below the mean”, and so on. This means that the two standardised variables are measured on a similar scale and their values are therefore directly comparable, which was not the case for the original unstandardised values.\nA coefficient of -0.43 associated with “standardised inequality” would therefore be interpreted as: a one-standard-deviation positive change in “standardised inequality” is associated with a below-half (around 40.3%) of a standard deviation negative change in “standardised trust”. In other words, it takes a difference of over two standard deviations (2.33) in inequality to observe a one-standard-deviation reduction in the level of trust.\nHowever, the purpose of the “correlation coefficient” is to provide a more general description of the association between two numeric variables. Its value ranges between -1 and 1, where 1 represents a perfect positive correlation between the two variables and -1 a perfect negative correlation, while 0 shows no correlation between the two at all. Visualising some of these extreme and intermediate correlations on scatter plots would look something like this:\n\n\n\n\n\n\n\n\n\n\nTo run a simple bivariate correlation analysis in JASP, go through the Menu tabs:\n\\[ \\text{Regression} \\longrightarrow \\text{[Classical] Correlation} \\] Move both of the variables of interest to the \\(\\text{Variables}\\) box.\nCheck if the results are the same as those obtained using linear regression\n\n\n\n\n\n\nSolution\n\n\n\nThe correlation output should look something like this:\n\n\n\n\n\nThis output was simplified by ticking the “Display pairwise” box in the Correlation options and un-ticking the “Report significance” option:\n\n\n\n\n\n\n\n\n\n\n\nNow we will build another simple bivariate regression model, but this time we will use the variable Region to model/explain/predict levels of “social trust” in different countries. Region is the only Nominal categorical variable in this dataset, and categorical variables behave differently in regression models.\n\n\nTip: You have done this a few times in previous workshops. Check back on previous exercises if you need to remind yourself of how to create a frequency table.\n\n\n\n\n\n\nSolution\n\n\n\nThe frequency table is:\n\n\n\n\n\n\n\n\n\n\nThe steps for fitting the regression, however, are very similar to what we have done in the previous exercise:\n\nClick through the Menu tabs:\n\n\\[ \\text{Regression} \\longrightarrow \\text{[Classical] Linear regression} \\]\n\nIn the Linear regression panel, move the “social trust” variable to the \\(\\text{Dependent Variable}\\) box\nBUT THIS TIME, we will move the Region variable to the \\(\\text{Factors}\\) box instead.\n\nThis will tell JASP that the Region variable is categorical and it should model it as such, treating each of its constituent categories as an individual factor/indicator variable, automatically leaving out the first category (Task 2.1 above will tell you which one that is!) from the model so that the left out category becomes the baseline/reference to which the coefficients on all the other categories compare. What happens here is that the left-out category is absorbed into the “Intercept” (the unknown/unmeasured variation in the dependent variable).\nThe results from the linear regression model will appear in the outputs window on the right.\n\n\n\n\n\n\nSolution\n\n\n\nThe modelling options chosen are:\n\n\n\n\n\nAnd the outputs from the model are:\n\n\n\n\n\n\n\n\n\n\nIn the case of numeric Scale-type predictor/independent variables the interpretation of the coefficient (“unstandardized”) was that a one-unit difference/change on the independent variable scale is associated with a difference/change in the dependent variable of the size shown by the value of the coefficient. When the predictor/independent variable is categorical, the interpretation changes somewhat. The coefficient associated with the listed category/level of the independent variable compares that category with the reference/baseline category. In other words, the unit of difference in this case is the difference between the stated and the reference category: being in the listed category as opposed to being in the reference category is associated with a difference/change in the dependent variable of the size shown by the value of the coefficient.\nBut what does this mean substantively in the context of our two variables?\n\nQuestions\n\nUsing the lecture slides and the assigned readings from Introduction to Modern Statistics (IMS), interpret the meaning of the regression coefficients on each reported level of the Region variable;\nWhich one is the “reference”/“baseline” category?\nAdd a note on the JASP output under the \\(\\text{Coefficients}\\) output and write down your interpretation there. [Tip: You’ve already practiced adding notes to the outputs in Workshop 1, Exercise 3, Point 7]\nWhere can you find the coefficient of correlation (\\(R\\)) in the outputs? What about the coefficient of determination (\\(R^2\\))? Are they meaningful in this context? Why so, or why not?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nIn order to interpret the regression results, we need to understand how our variables are measured and coded. We already know everything we have to about the trust_pct variable from Exercise 1. To understand the Region variable, we should inspect the frequency table produced in Task 2.1 above. We see there that the variable has 7 non-missing (valid) categories, and if we look at the regression output, we see that only 6 are listed in the Coefficients table: the first category (“Europe & Central Asia”) is missing. Well, it’s not actually missing, but it was “absorbed” into the (Intercept). What this means is that the meaning of the (Intercept) in this case is: the average value of trust_pct when the value of Region is “Europe & Central Asia”; or, put differently, the (Intercept) denotes the average trust_pct in the European and Central Asian countries present in the dataset.\nWhat happens when we enter a categorical variable as a predictor (independent variable) into a linear regression model in JASP (and most other statistical computing packages) is that the regression function automatically breaks the categorical variable into several “dummy” or “indicator” variables, one for each constituent category, that indicate membership (or not) in that category, and the first category is left out of the model so that all other categories can compare to this left-out “reference” or “base-line” category. Put differently, we have not one but six different predictors/independent variables in this model, each taking the value of 1 if the observation falls into that category and the value of 0 if it does not. For example, the observation “Australia” has a value of 0 on the “Region (Latin America & Caribbean)” variable, but a value of 1 on the “Region (East Asia & Pacific)” variable, and 0 on all other listed variables. The United Kingdom has a value of 0 on all six variables listed in the Coefficients table, because it has a value of 1 on the “Region (Europe & Central Asia)” variable, which was left out from among the predictors and to which all other variables compare.\nThe regression coefficients are therefore interpreted as comparisons to “Europe & Central Asia”. For example, the coefficient of -20.11 on “Latin America & Caribbean” means that the expected value of trust_pct of a country in Latin America or the Caribbean is 20.11% lower, on average, than the expected trust_pct value of a country in Europe or Central Asia. The only regions where we expect to see higher average social trust than in “Europe & Central Asia” are “East Asia & Pacific” (2.1% higher) and “North America” (13,6% higher). In other regions, the expected average level of social trust is lower than in Europe & Central Asia by the displayed coefficient.\nWhere can you find the coefficient of correlation (\\(R\\))? What about the coefficient of determination (\\(R^2\\))? Are they meaningful in this context?\nAs we can see, the correlation coefficient no longer appears in the “Standardized” coefficients column in the Coefficients table. The reason is explained in the table. The correlation coefficient also loses its meaning in the context of a multiple regression model in which we have more than one predictor/independent/explanatory variable. It’s meaning becomes “partial” to all the other variables in the model. In this case, its squared value, the R2 is more meaningful: it captures, roughly, the amount (percentage) of the variance in the dependent variable that is explained by the whole model, with all the predictors included. Here, we could say that Region is able to explain 27.1% of the variation in the “social trust” across countries (R2=0.271; to express that as a percentage, we multiply it by 100; i.e. we move the decimal point two places to the right).\n\n\n\n\n\n\nWe can now combine the separate bivariate analyses in the previous two exercises into a more elaborate multiple regression model. The procedure to build a multiple regression model is the same as in the simple regression models before, but this time we add both of the independent variables into the model:\n\\[ \\text{MENU TABS: } \\text{Regression} \\longrightarrow \\text{[Classical] Linear regression} \\]\n\nIn the Linear regression panel, move the “social trust” variable to the \\(\\text{Dependent Variable}\\) box\nMove the “inequality” variable to the \\(\\text{Covariates}\\) box\nMove the Region variable to the \\(\\text{Factors}\\) box\n\nThe results will appear in the outputs window on the right. We now have a statistical model which explains variation in “social trust” not only dependent on “inequality”, but also on “Region”. Put differently - if our main aim is to estimate how “inequality” is associated with “social trust” - we have obtained a more accurate estimate of the association between “inequality” and “social trust”, while also accounting for variation due to differences in the Region to which countries belong.\nAnother way in which this is often expressed is that the stated coefficients are those obtained after we keep constant or eliminate the effect of the other variables in the model. This procedure is expected to give us more accurate estimates because by including further variables into the model, we have removed them from the pool of the “unknown” factors affecting/related to out outcome measurement of interest.\n\nQuestions\n\nUsing the lecture slides and the assigned readings from Introduction to Modern Statistics (IMS), interpret the meaning of each regression coefficient, comparing them with the ones obtained from the simpler models in the previous exercises;\nAdd a note on the JASP output under the \\(\\text{Coefficients}\\) output and write down your interpretations there.\nWhere can you find the coefficient of correlation (\\(R\\)) in the outputs? What about the coefficient of determination (\\(R^2\\))? Are they meaningful in this context? Why so, or why not?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThe regression model options chosen are:\n\n\n\n\n\nAnd the resulting output is:\n\n\n\n\n\nThe interpretation of the coefficients here is a combination of the interpretations given in Exercise 1 and Exercise 2. The only difference is that each coefficient tells us the expected difference in the value of trust_pct associated with the given predictor while the values of all the other predictors in the model are kept constant (i.e. their effect is nullified, taken out of the equation). This means that the coefficient of -3.63 for inequality_s80s20 is a more precise estimate of the impact of “inequality” on “social trust” that the coefficient of -3.11 obtained in the simplem regression model in Exercise 1, because this coefficient now also accounts for the expected effect of a country belonging to a given world Region. Vice-versa, compared to the coefficients we saw in Exercise 2, the coefficients for Region seen here are a more precise estimation of the expected effect of belonging to a Region because that effect now also accounts for variation in inequality_s80s20 between the various regions. In fact, we do see some markedly different Region coefficients than in the simple model, now that we have “controlled” for the effect of “inequality” in the model as well.\nLooking at the R2 value we also find that this has increased to 0.346, indicating that the combined knowledge of the Region as well as the inequality_s80s20 score of a country can help explain 34.6% of the variation in trust_pct. The remaining 65%+ of the variation is associated with other factors that our model is not considering (maybe “crime rates”, or “recent history of civil war”, or “ethno-racial diversity/fragmentation”? If we have variables measuring these phenomena, then we could consider including them in our model).\n\n\n\n\n\nLet’s look again at the assignment research questions. Some of these questions imply a dependent variable which is measured as a numeric scale or at least a long-ish (e.g. 7-point +) ordinal scale in one of the surveys we will use for the assignment (ESS10, WVS7, EVS2017). Other questions imply dependent variables that are more strictly categorical, and as such, we cannot model them using linear regression. For those, we may be able to apply another model type that better fits that kind of outcome variable (e.g. logistic regression), one of which we will be covering in Week 5.\nIn this exercise, explore the survey questionnaires (like we did in previous Workshops) to identify any available variables for answering one/some of the questions below, and check how the implied dependent variable was measured:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?\n\nThe best way to explore the available Assignment datasets and questionnaires is via the Data page of this site."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w3.html#learning-outcomes",
    "href": "Materials/Worksheets/draft_worksheet_w3.html#learning-outcomes",
    "title": "Workshop 3 Worksheet",
    "section": "",
    "text": "By the end of the session, you should be familiar with:\n\nrunning simple and multiple linear regression in JASP\nperforming a correlation analysis in JASP\nmodel building in JASP\nthe interpretation of linear regression coefficients"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w3.html#intro",
    "href": "Materials/Worksheets/draft_worksheet_w3.html#intro",
    "title": "Workshop 3 Worksheet",
    "section": "",
    "text": "We continue where we left off in the last Workshop, taking further Workshop 2 Worksheet - Exercise 2 in which we made a scatter plot of inequality by social trust using the Trust & Inequality (trust_inequality.dta) dataset, which can be downloaded from https://cgmoreh.github.io/SOC2069-QUANT/Data/.\nIn that exercise we simplified the default output by removing the univariate distributions of the variables displayed on the margins and the regression line cutting through the plot. Now, however, we will focus on understanding what that “regression line” is actually telling us.\n\n\n\n\n\n\nSolutions\n\n\n\nA JASP file with the solutions to the exercises can be downloaded from HERE."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w3.html#exercise-1-from-a-regression-line-to-regression-coefficients",
    "href": "Materials/Worksheets/draft_worksheet_w3.html#exercise-1-from-a-regression-line-to-regression-coefficients",
    "title": "Workshop 3 Worksheet",
    "section": "",
    "text": "If you haven’t yet downloaded it in the last workshop, download the Trust & Inequality (trust_inequality.dta) dataset from https://cgmoreh.github.io/SOC2069-QUANT/Data/\n\n\nAs a first step, create a scatter plot visualising the “relationship” (co-variation, joint distribution, …) between social trust (trust_pct) and inequality (inequality_s80s20). This is Exercise 2 from Workshop 2 - if you need a reminder of how to do it, check Workshop 2 Worksheet - Exercise 2 or your saved .jasp file containing your workshop analysis from Workshop 2.\n\n\n\nNow let’s dig deeper into the meaning of the regression line by building a simple bivariate linear regression model of social trust as a function of societal inequality (i.e. a model aiming to explain/predict values of social trust in various countries depending on the value of societal inequality in those countries).\nTo build a linear regression model in JASP, click through the Menu tabs:\n\\[ \\text{Regression} \\longrightarrow \\text{[Classical] Linear regression} \\] In the Linear regression panel, move the “social trust” variable to the \\(\\text{Dependent Variable}\\) box and the “inequality” variable to the \\(\\text{Covariates}\\) box.\nThe results from the linear regression model will appear in the outputs window on the right.\n\n\n\n\n\n\nSolution\n\n\n\nThe output should look something like this:\n\n\n\n\n\n\n\n\n\n\nIn general terms, the coefficient of interest (the one associated with the independent variable) tells us: that a one-unit difference/change on the independent variable scale is associated with a difference/change in the dependent variable of the size shown by the value of the coefficient.\nBut what does this mean substantively in the context of our two variables?\n\nQuestions\n\nUsing the lecture slides and Chapter 7 (“Linear regression with a single predictor”) from the Introduction to Modern Statistics (IMS), interpret the meaning of the regression coefficient on “inequality”.\nAdd a note on the JASP output under the \\(\\text{Coefficients}\\) output and write down your interpretation there. [Tip: You’ve already practiced adding notes to the outputs in Workshop 1, Exercise 3, Point 7]\nWhere can you find the coefficient of correlation (\\(R\\)) in the outputs? What about the coefficient of determination (\\(R^2\\))?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThe tables in the outputs list results from two “models”. One is a model without any explanatory (independent/predictor) variables (M0), in which case the (Intercept) value is nothing else then the average (mean) value of the outcome (dependent/explained) variable calculated on the sample of cases/observations (i.e. countries here) that were included in the model (i.e. only those who had a valid measurement on both of the variables, so a non-missing value for both the “trust” and the “inequity” variable). This “null model” is given to us by JASP by default, without us asking for it. The model we actually fit is presented as M1, and this is what we are interested in. As we see in the Coefficients table, the coefficient associated with the (Intercept) value in M1 is no longer the mean/average level of trust_pct, but instead 45.384. This value represents the expected score on the dependent variable (trust_pct) when the value of the independent variable (inequality_s80s20) is 0. As it will become apparent from the discussion below, a value of 0 for the inequality_s80s20 variable is highly unrealistic, and this is often the case. However, that’s not a problem, because the (Intercept) value is meant to provide a mathematical baseline to the model and we generally are not interested in interpreting it., so we won’t. What we are interested in is the coefficient on our independent (explanatory/predictor) variable.\nWhat is the meaning of the regression coefficient on “inequality”?\nIn general terms, the coefficient of interest (the one associated with the independent variable) tells us: that a one-unit difference/change on the independent variable scale is associated with a difference/change in the dependent variable of the size shown by the value of the coefficient.\nBut what does this mean substantively in the context of our two variables?\nFrom the Coefficients table we see that the regression coefficient associated with our predictor/independent variable is -3.114. This tells us that a one-unit increase on the “inequality” scale is associated with a -3.114-unit change on the “trust” scale. To give this a more meaningful interpretation, we need to know what exactly a unit change means on each scale, and for that we need to know what our variables measure.\nUnderstanding the “trust” measurement (the trust_pct variable) is more straightforward. We know that it measures the percentage of respondents in each country who answered that “in general, most people can be trusted” to the standard social trust survey question in the World Values Survey. A unit on that scale is therefore one percentage-point.\nUnderstanding the “inequality” scale is much trickier, because that scale measures a ratio. Specifically, it denotes the so-called income quintile share ratio, a commonly employed measurement of inequality in the income distribution in a country. It is calculated as the ratio of total income received by the 20% of the population with the highest income (the top quintile) to that received by the 20% of the population with the lowest income (the bottom quintile) [By the way, a “quintile” (from the Latin word “quintus” for “five”) is simply a value that divides a scale into five equal parts - e.g. a scale of all the integers between 0 and 100 divided into five equal parts will contain 20 integers in each part, i.e. 100÷5]. In our dataset, the variable measuring it - inequality_s80s20 - was calculated by taking the ratio of (i.e. dividing) the variables income_top20 and income_bottom20. For example, looking at the first entry, for Albania, we see that income_top20 = 39.6375 and income_bottom20 = 7.9125, so inequality_s80s20 will be 39.6÷7.9 = 5.009478673 (or 5.01 rounded up to two decimal points).\nThat’s fairly easy to get our heads around, but because its unit of measurement is a ratio it also makes it more difficult to compare one value to another. The best way of approaching it is through some logical examples. Say, for instance, that we want to posit the existence of a perfectly equal society (in terms of income distribution, at least). What would that entail? It would entail that the top-20% earners and the bottom-20% earners own the same share of the total available income. For example, if the top-20% possess 20% of the income distribution and the bottom-20% also possess 20% of the income distribution (with the remaining 60% of income possessed by the middle-60% of earners), then the inequality ratio would be 20÷20=1. The ratio is the same if the “middle-class” is very thin and both the top- and the bottom-20% of earners possess, say, 42% of the income distribution (84% in total): 42÷42=1. To generalise, when two values are equal, their ratio is 1. But what happens if we hypothesise a very unequal society, say one in which the top-20% of the earners share 90% of all income distributed within an economy, while the bottom-20% share on only 0.5% of the income distribution? In such a scenario, the inequality ratio would be 90÷0.5=180; and, in theory, the value of this ratio can be limitlessly high (e.g. 99.999÷0.00005=1,999,980; yes, that is indeed almost 2 million!). The larger the gap, the more extreme the ratio value, and the change between values is not “linear”.\nHowever, the above scenarios are empirically unrealistic. In fact, if we look at our actual data, the lowest share of the income scale possessed by the top-20% in any country is 34.56 (Slovakia), while the highest share is 57.3 (Brazil). For income possessed by the bottom-20%, the lowest percentage is 3.45 (Brazil) and the highest value is 10.08 (Ukraine). In terms of inequality_s80s20, we then see the lowest value at 3.52 (Ukraine) and the highest at 16.64 (Brazil). On this more restricted empirical scale (running from 3.52 to 16.64), the difference between the values is more equal, making the changes from one value to another approximately linear.\nSo, then, what does a one-unit change on this “empirical” scale mean? It means, for example, the difference between an inequality score of 30÷10=3 and one of 24÷6=4; or, approximately, between 40÷7.9=5.06 (Lebanon) and 42.83÷7.08=6.05 (Nigeria). It is, in other words, a rather large unit; the entire scale (running from 3.52 to 16.64) contains just over 13 such units (16.64 - 3.52 = 13.12). By contrast, a percentage scale contains 100 units of 1%-point each. Due to such differences in the scales that are being compared, it is very common to “standardise” the variables used in a regression so that each unit involved is “equal”. On the other hand, the difficulty is then shifted onto interpreting those standardized coefficients on the original meaningful scale of the variables involved. In other words, it’s a challenge either way. In this exercise, we have left the two variables involved in the regression unstandardised, so a “unit” has a different meaning in the case of each variable.\nNow, having thought deeply about what the variables involved actually measure, we can interpret the regression coefficient, which is telling us that our simple model predicts that a country with an inequality score 1 points higher than that of another country will have, on average, a trust score 3.114% lower than that other country. If we look, for example, at the trust scores of Lebanon and Nigeria, we can get a sense of how well our model does at predicting this specific case: 12.68% - 9.92% = 2.76%. It’s not a perfect prediction, but it’s a much better one than we could have made had we not had any information on “inequality”. Ultimately, our model helps us make a better informed assessment of the variability in trust across countries, even if it will either overestimate or underestimate any given actual value.\nWhere can you find the coefficient of correlation (\\(R\\)) in the outputs?\nThe idea behind the coefficient of correlation (\\(R\\)) relates somewhat to the discussion above regarding “standardisation”. In fact, the correlation coefficient is calculated by standardising the scales of the two variables involved (trust_pct and inequality_s80s20) and expressing the coefficient on that standardised scale. In our JASP output, we can find this information under the Standardized column in the Coefficients table, and as an absolute value (i.e. non-negative) is shown under the R column in the Model Summary table.\nBut what exactly does “standardisation” mean?\nOne of the most commonly employed “standard scores” is the z-score, which tells us how many “standard deviations” (SD) each score/value is from the mean/average score/value on a given measurement scale. The ﻿\\(z\\)-score for a value \\(x\\)﻿ is calculated as \\(z_x={(x-\\mu_X)\\over\\sigma_X}\\) ﻿, where \\(x\\)﻿ is any single value on a scale \\(X\\), \\(\\mu_X\\) is the mean/average of \\(X\\) and \\(\\sigma_X\\) is the standard deviation of \\(X\\). In JASP, we can use the zScores() drag-and-drop function to calculate this. If we were to create two new variables that are the z-standardised versions of the trust_pct and inequality_s80s20 variables, respectively, and we ran the same regression as above on those variables, then the obtained regression coefficient on “standardised inequality” would have coincided with the correlation coefficient and it would have been -0.430.1 On these newly standardized scales, a value of 1 means “one standard deviation above the mean”, a value of 2 means “two standard deviations above the mean”, a value of -1 means “one standard deviation below the mean”, and so on. This means that the two standardised variables are measured on a similar scale and their values are therefore directly comparable, which was not the case for the original unstandardised values.\nA coefficient of -0.43 associated with “standardised inequality” would therefore be interpreted as: a one-standard-deviation positive change in “standardised inequality” is associated with a below-half (around 40.3%) of a standard deviation negative change in “standardised trust”. In other words, it takes a difference of over two standard deviations (2.33) in inequality to observe a one-standard-deviation reduction in the level of trust.\nHowever, the purpose of the “correlation coefficient” is to provide a more general description of the association between two numeric variables. Its value ranges between -1 and 1, where 1 represents a perfect positive correlation between the two variables and -1 a perfect negative correlation, while 0 shows no correlation between the two at all. Visualising some of these extreme and intermediate correlations on scatter plots would look something like this:\n\n\n\n\n\n\n\n\n\n\nTo run a simple bivariate correlation analysis in JASP, go through the Menu tabs:\n\\[ \\text{Regression} \\longrightarrow \\text{[Classical] Correlation} \\] Move both of the variables of interest to the \\(\\text{Variables}\\) box.\nCheck if the results are the same as those obtained using linear regression\n\n\n\n\n\n\nSolution\n\n\n\nThe correlation output should look something like this:\n\n\n\n\n\nThis output was simplified by ticking the “Display pairwise” box in the Correlation options and un-ticking the “Report significance” option:"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w3.html#exercise-2-linear-regression-with-categorical-predictors",
    "href": "Materials/Worksheets/draft_worksheet_w3.html#exercise-2-linear-regression-with-categorical-predictors",
    "title": "Workshop 3 Worksheet",
    "section": "",
    "text": "Now we will build another simple bivariate regression model, but this time we will use the variable Region to model/explain/predict levels of “social trust” in different countries. Region is the only Nominal categorical variable in this dataset, and categorical variables behave differently in regression models.\n\n\nTip: You have done this a few times in previous workshops. Check back on previous exercises if you need to remind yourself of how to create a frequency table.\n\n\n\n\n\n\nSolution\n\n\n\nThe frequency table is:\n\n\n\n\n\n\n\n\n\n\nThe steps for fitting the regression, however, are very similar to what we have done in the previous exercise:\n\nClick through the Menu tabs:\n\n\\[ \\text{Regression} \\longrightarrow \\text{[Classical] Linear regression} \\]\n\nIn the Linear regression panel, move the “social trust” variable to the \\(\\text{Dependent Variable}\\) box\nBUT THIS TIME, we will move the Region variable to the \\(\\text{Factors}\\) box instead.\n\nThis will tell JASP that the Region variable is categorical and it should model it as such, treating each of its constituent categories as an individual factor/indicator variable, automatically leaving out the first category (Task 2.1 above will tell you which one that is!) from the model so that the left out category becomes the baseline/reference to which the coefficients on all the other categories compare. What happens here is that the left-out category is absorbed into the “Intercept” (the unknown/unmeasured variation in the dependent variable).\nThe results from the linear regression model will appear in the outputs window on the right.\n\n\n\n\n\n\nSolution\n\n\n\nThe modelling options chosen are:\n\n\n\n\n\nAnd the outputs from the model are:\n\n\n\n\n\n\n\n\n\n\nIn the case of numeric Scale-type predictor/independent variables the interpretation of the coefficient (“unstandardized”) was that a one-unit difference/change on the independent variable scale is associated with a difference/change in the dependent variable of the size shown by the value of the coefficient. When the predictor/independent variable is categorical, the interpretation changes somewhat. The coefficient associated with the listed category/level of the independent variable compares that category with the reference/baseline category. In other words, the unit of difference in this case is the difference between the stated and the reference category: being in the listed category as opposed to being in the reference category is associated with a difference/change in the dependent variable of the size shown by the value of the coefficient.\nBut what does this mean substantively in the context of our two variables?\n\nQuestions\n\nUsing the lecture slides and the assigned readings from Introduction to Modern Statistics (IMS), interpret the meaning of the regression coefficients on each reported level of the Region variable;\nWhich one is the “reference”/“baseline” category?\nAdd a note on the JASP output under the \\(\\text{Coefficients}\\) output and write down your interpretation there. [Tip: You’ve already practiced adding notes to the outputs in Workshop 1, Exercise 3, Point 7]\nWhere can you find the coefficient of correlation (\\(R\\)) in the outputs? What about the coefficient of determination (\\(R^2\\))? Are they meaningful in this context? Why so, or why not?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nIn order to interpret the regression results, we need to understand how our variables are measured and coded. We already know everything we have to about the trust_pct variable from Exercise 1. To understand the Region variable, we should inspect the frequency table produced in Task 2.1 above. We see there that the variable has 7 non-missing (valid) categories, and if we look at the regression output, we see that only 6 are listed in the Coefficients table: the first category (“Europe & Central Asia”) is missing. Well, it’s not actually missing, but it was “absorbed” into the (Intercept). What this means is that the meaning of the (Intercept) in this case is: the average value of trust_pct when the value of Region is “Europe & Central Asia”; or, put differently, the (Intercept) denotes the average trust_pct in the European and Central Asian countries present in the dataset.\nWhat happens when we enter a categorical variable as a predictor (independent variable) into a linear regression model in JASP (and most other statistical computing packages) is that the regression function automatically breaks the categorical variable into several “dummy” or “indicator” variables, one for each constituent category, that indicate membership (or not) in that category, and the first category is left out of the model so that all other categories can compare to this left-out “reference” or “base-line” category. Put differently, we have not one but six different predictors/independent variables in this model, each taking the value of 1 if the observation falls into that category and the value of 0 if it does not. For example, the observation “Australia” has a value of 0 on the “Region (Latin America & Caribbean)” variable, but a value of 1 on the “Region (East Asia & Pacific)” variable, and 0 on all other listed variables. The United Kingdom has a value of 0 on all six variables listed in the Coefficients table, because it has a value of 1 on the “Region (Europe & Central Asia)” variable, which was left out from among the predictors and to which all other variables compare.\nThe regression coefficients are therefore interpreted as comparisons to “Europe & Central Asia”. For example, the coefficient of -20.11 on “Latin America & Caribbean” means that the expected value of trust_pct of a country in Latin America or the Caribbean is 20.11% lower, on average, than the expected trust_pct value of a country in Europe or Central Asia. The only regions where we expect to see higher average social trust than in “Europe & Central Asia” are “East Asia & Pacific” (2.1% higher) and “North America” (13,6% higher). In other regions, the expected average level of social trust is lower than in Europe & Central Asia by the displayed coefficient.\nWhere can you find the coefficient of correlation (\\(R\\))? What about the coefficient of determination (\\(R^2\\))? Are they meaningful in this context?\nAs we can see, the correlation coefficient no longer appears in the “Standardized” coefficients column in the Coefficients table. The reason is explained in the table. The correlation coefficient also loses its meaning in the context of a multiple regression model in which we have more than one predictor/independent/explanatory variable. It’s meaning becomes “partial” to all the other variables in the model. In this case, its squared value, the R2 is more meaningful: it captures, roughly, the amount (percentage) of the variance in the dependent variable that is explained by the whole model, with all the predictors included. Here, we could say that Region is able to explain 27.1% of the variation in the “social trust” across countries (R2=0.271; to express that as a percentage, we multiply it by 100; i.e. we move the decimal point two places to the right)."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w3.html#exercise-3-build-a-multiple-regression-model",
    "href": "Materials/Worksheets/draft_worksheet_w3.html#exercise-3-build-a-multiple-regression-model",
    "title": "Workshop 3 Worksheet",
    "section": "",
    "text": "We can now combine the separate bivariate analyses in the previous two exercises into a more elaborate multiple regression model. The procedure to build a multiple regression model is the same as in the simple regression models before, but this time we add both of the independent variables into the model:\n\\[ \\text{MENU TABS: } \\text{Regression} \\longrightarrow \\text{[Classical] Linear regression} \\]\n\nIn the Linear regression panel, move the “social trust” variable to the \\(\\text{Dependent Variable}\\) box\nMove the “inequality” variable to the \\(\\text{Covariates}\\) box\nMove the Region variable to the \\(\\text{Factors}\\) box\n\nThe results will appear in the outputs window on the right. We now have a statistical model which explains variation in “social trust” not only dependent on “inequality”, but also on “Region”. Put differently - if our main aim is to estimate how “inequality” is associated with “social trust” - we have obtained a more accurate estimate of the association between “inequality” and “social trust”, while also accounting for variation due to differences in the Region to which countries belong.\nAnother way in which this is often expressed is that the stated coefficients are those obtained after we keep constant or eliminate the effect of the other variables in the model. This procedure is expected to give us more accurate estimates because by including further variables into the model, we have removed them from the pool of the “unknown” factors affecting/related to out outcome measurement of interest.\n\nQuestions\n\nUsing the lecture slides and the assigned readings from Introduction to Modern Statistics (IMS), interpret the meaning of each regression coefficient, comparing them with the ones obtained from the simpler models in the previous exercises;\nAdd a note on the JASP output under the \\(\\text{Coefficients}\\) output and write down your interpretations there.\nWhere can you find the coefficient of correlation (\\(R\\)) in the outputs? What about the coefficient of determination (\\(R^2\\))? Are they meaningful in this context? Why so, or why not?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nThe regression model options chosen are:\n\n\n\n\n\nAnd the resulting output is:\n\n\n\n\n\nThe interpretation of the coefficients here is a combination of the interpretations given in Exercise 1 and Exercise 2. The only difference is that each coefficient tells us the expected difference in the value of trust_pct associated with the given predictor while the values of all the other predictors in the model are kept constant (i.e. their effect is nullified, taken out of the equation). This means that the coefficient of -3.63 for inequality_s80s20 is a more precise estimate of the impact of “inequality” on “social trust” that the coefficient of -3.11 obtained in the simplem regression model in Exercise 1, because this coefficient now also accounts for the expected effect of a country belonging to a given world Region. Vice-versa, compared to the coefficients we saw in Exercise 2, the coefficients for Region seen here are a more precise estimation of the expected effect of belonging to a Region because that effect now also accounts for variation in inequality_s80s20 between the various regions. In fact, we do see some markedly different Region coefficients than in the simple model, now that we have “controlled” for the effect of “inequality” in the model as well.\nLooking at the R2 value we also find that this has increased to 0.346, indicating that the combined knowledge of the Region as well as the inequality_s80s20 score of a country can help explain 34.6% of the variation in trust_pct. The remaining 65%+ of the variation is associated with other factors that our model is not considering (maybe “crime rates”, or “recent history of civil war”, or “ethno-racial diversity/fragmentation”? If we have variables measuring these phenomena, then we could consider including them in our model)."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w3.html#exercise-4-take-home-which-of-the-assignment-research-questions-could-be-addressed-using-a-linear-regression-model",
    "href": "Materials/Worksheets/draft_worksheet_w3.html#exercise-4-take-home-which-of-the-assignment-research-questions-could-be-addressed-using-a-linear-regression-model",
    "title": "Workshop 3 Worksheet",
    "section": "",
    "text": "Let’s look again at the assignment research questions. Some of these questions imply a dependent variable which is measured as a numeric scale or at least a long-ish (e.g. 7-point +) ordinal scale in one of the surveys we will use for the assignment (ESS10, WVS7, EVS2017). Other questions imply dependent variables that are more strictly categorical, and as such, we cannot model them using linear regression. For those, we may be able to apply another model type that better fits that kind of outcome variable (e.g. logistic regression), one of which we will be covering in Week 5.\nIn this exercise, explore the survey questionnaires (like we did in previous Workshops) to identify any available variables for answering one/some of the questions below, and check how the implied dependent variable was measured:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?\n\nThe best way to explore the available Assignment datasets and questionnaires is via the Data page of this site."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w3.html#footnotes",
    "href": "Materials/Worksheets/draft_worksheet_w3.html#footnotes",
    "title": "Workshop 3 Worksheet",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI demonstrate what “standardization” using z-scores means in the JASP file containing the solution analysis, available here.↩︎"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w1.html",
    "href": "Materials/Worksheets/draft_worksheet_w1.html",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "By the end of the session you will have gained familiarity with:\n\nsome important cross-national survey programmes\nhow to find, download and read data documentation, including survey questionnaires\nthe challenges of measuring sociological concepts\nthe JASP interface\n\n\n\n\nThe lecture has introduced the complexities of measuring sociological concepts. Throughout this short course, we will be using the measurement and estimation of social trust as a guiding example. However, the aim is to help you build up your skills and confidence in asking and addressing research questions of your own, and the assessment questions will ask you to analyse some other chosen research topic.\nIn this first workshop, you will begin your data analysis journey by exploring some online sources of cross-national sociological data available for secondary analysis, and you will practice performing basic descriptive analyses of selected variables.\n\n\n\nCreate a folder for this module on your institutional OneDrive (e.g. C:\\OneDrive - Newcastle University\\SOC2069). Within that folder, create a sub-folder called “Data”. You will then be able to save data files and documentation as you progress.\n\n\n\nAbout 20 minutes\n\nNavigate to the The World Values Survey (WVS) website and read about the World Values Survey.\n\n\nDon’t spend too much time browsing the website, but make sure you can answer the following questions:\n\nWhen was the WVS started, and how many waves of data collection have there been so far?\nIn which year(s) did the most recent wave of data collection take place?\nHow many countries were covered by the most recent wave?\nCan you name some of the topics covered by the WVS?\nWhat population are the national samples representative of?\nWhat is the general minimum sample size per country?\nIs the WVS data freely available for academic research purposes?\nDo you need to cite/reference the WVS data if you use it in your research?\nBonus: what is the difference between a time series dataset and a panel dataset, and which of the two can the WVS provide? (tip: look under Data and Documentation &gt; Data Download &gt; Timeseries (1981-2022) for a concise discussion)\n\n\n\nNavigate to Data and Documentation &gt; Data Download &gt; Wave 7 (2017-2022) page and explore the Questionnaire and Documentation. Download the Master Questionnaire and the Codebook documents and using the search function identify all the survey questions and variables that relate to “trust”.\n\n\nQuestions\n\nHow many questions relating to trust have you identified in the questionnaires?\nWhat is the difference between the questionnaire and the codebook?\nIn how many different ways is trust measured in the WVS?\nWhat are, in your opinion, the advantages and disadvantages of the different measurements of trust?\n\n\n\nWithin the “Data” sub-folder you created earlier, create another sub-folder called “WVS7”. You can now save the Master Questionnaire and the Codebook into that folder, and because it is stored on the institutional OneDrive, you will always have access to it on any computer, once you log in to your institutional Microsoft Windows account.\nIn the Select a country panel on the right side of the Wave 7 (2017-2022) page select one country at random and under Data files download the country-specific dataset (for consistency, download the first data type option, CSV (i.e. comma separated values)) to the “WVS7” subfolder you created earlier.\n\n\n\n\nAbout 20 minutes\nLet’s now navigate to The European Social Survey (ESS) and read about the survey. Try to answer to yourself the same questions as in the previous exercise\n\nNavigate to Data and then to the ESS Data Portal &gt; ESS Round 10 - 2020 &gt; ESS10 - Study Documentation. Download the ESS10 Source questionnaires to a newly created sub-folder called “ESS10”, and as in the previous exercise, identify all the survey questions and variables that relate to “trust”.\nNavigate to ESS Data Portal &gt; Datafile Builder (Wizard) and select one country at random at Round 10 (or 10SC). Keep all the variables (do not select any subsets in the “Select Variables” tab) and download the country-specific dataset in CSV format to your “ESS10” folder.\n\n\n\n\n\n\n\nNote\n\n\n\nTo be able to download data, you will need to register with the European Social Survey. Complete the registration before you can proceed\n\n\nYou now have a large amount of data at your fingertips. After a break, we will explore these data using a statistical software package\n\n\n\nAbout 30 minutes\nOpen the JASP software from the Start menu. If you are using your own laptop, you can install the latest version of JASP from https://jasp-stats.org/.\nThe opening page should look something like this:\n\n\n\n\n\nTo open a dataset stored on your computer, you can navigate to the three horizontal bars (“hamburger”) menu icon &gt; Open &gt; Computer &gt; Browse.\n\n\n\n\n\n\nNote\n\n\n\nTo be able to see and load the data you downloaded from the WVS and ESS, you need to first extract the files from the compressed folder. Navigate to your Data folder outside the JASP data import window and extract your files, then return to the JASP window to open one of them.\n\n\n\nOpen the “WVS7” dataset. You should now see something like this:\n\n\n\n\n\n\nYou can scroll up-down and left-right in the dataset to have a look at the spreadsheet and its contents.\nIn JASP you can work on one dataset at a time (or in one window). When you finish your analysis, you can save both the data and the outputs you generated as one .jasp file, which you can then open later and continue or alter your analyses.\nToday, we will explore some descriptive statistics using the Descriptives &gt; Descriptive Statistics menu option. If you click through, you should see something like this:\n\n\n\n\n\n\nUsing the survey questionnaire, identify the variable coding “social/generalised trust” and move that variable to the Variables field\nApart from the default Descriptive Statistics table, select Basic plots &gt; Distribution plots as well and interpret the distribution of the variable in your dataset\n\n\nQuestions\n\nHow many levels (categories) does the variable have in your dataset? is it what you had expected based on the questionnaire information?\nDoes the variables have any missing values in your dataset?\nWhat is the “Mode” of the variable, and what does that mean?\nWhat is the “Mean” of the variable, and what does that mean? Is it a useful statistic for this variable?\nWhat percentage of the respondents in your dataset had answered that “Most people can be trusted”?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nUsing the WVS7 dataset for the United Kingdom, and having identified the “social trust” variable from the Questionnaire and/or Codebook to be named “Q57” in the dataset, we obtain the following descriptive statistics:\n\n\n\n\n\n\nThere appear to be 3 levels in the variables. Form the questionnaire we know that there should be 2 valid categories only: 1 (Most people can be trusted) and 2 (Need to be very careful);\nFrom the Codebook we know that there may be some other values coded by the researchers as well: -1 for “Don´t know”, -2 for “No answer”, -4 for “Not asked” and -5 for “Missing”. These are coded with negative values in order to stand out as non-standard categories of answers. They code various reasons for why values may be “missing” in the dataset. In the UK dataset we are using here we have three of these values present;\nBy looking at the distribution plot, we see that the tallest bar (the largest answer category) is the one coded as 2. The largest (most common) category of a categorical variables is called the “mode”. We can also request for the “mode” the “median” and other potentially informative summary statistics to also be included in the Descriptive Statistics table by ticking the appropriate boxes under the Statistics option-bar in the Descriptive Statistics builder on the left hand side:\n\n\n\nAccording to the Descriptive Statistics table the mean of the variable is 1.488. However, in this case this is not a sensible statistic. First of all, we have a categorical variable, so an average value between 1 (Most people can be trusted) and 2 (Need to be very careful) does not mean much. If anything, in the case of only two categories, we know that if category 1 and category 2 are of equal size (i.e. the same number of people have answered each of them), then the mean would be \\({1 + 2 \\over 2} = 1.5\\), so a mean of 1.48 would indicate that the category coded as 1 is slightly larger. However, secondly, in our case we also have the several negative values that are also added up in the calculation of the mean. Under these circumstances, the mean cannot tell us anything accurate or useful.\nTo get a more precise percentage of the distribution of the answer options (categories) across the variable, we would need to request a Frequency table in the Descriptive Statistics builder, which we can do under the Tables option-bar:\n\nThe result would be:\n\nWe therefore find that almost 46% of the respondents in the dataset had answered that “Most people can be trusted”. However, this also counts with all the “missing” responses. If we would like to get a more accurate values for the “Valid Percent” (i.e. the percentage distribution among only those with valid response options, 1 or 2), then we will need to tell JASP to consider the negative values as “missing”.\n\n\n\nIf you see more than two levels/categories in your variable (and you are sure that you have chosen the correct variable), it means that in your dataset the variable contains some custom missing values. Missing values should be distinguished with a negative sign (e.g. -2). To set them as custom missing values, we can edit the dataset manually.\n\nClick on the Edit Data menu tab and scroll horizontally to your variable. Double-click on the variable column. In the middle tabs, check the label editor and identify any values that should be set as missing (e.g. -2). Click on the Missing values tab &gt; Use custom values and in the narrow field to the right type in the value you want to set as missing and click the + sign. You should be seeing something like below:\n\n\n\n\n\n\nYou can check back in the Label editor that the redundant value is not longer there.\n\nIn the same data editor window we can also make other changes to our variables. For example, let’s change the non-informative variable Name to something that better reflects the meaning of the variable, for example “soc-trust”, and let’s also give it a more descriptive Long name and even a Description if we want to. The Long name could be something like “Social trust”, and for the Description we could copy the original survey question out from the questionnaire: “Q57. Generally speaking, would you say that most people can be trusted or that you need to be very careful in dealing with people?”.\n\nIn the Label editor we should also attach labels to the values so that we can better read the outputs produced. We can copy the labels from the questionnaire here too: “1 = Most people can be trusted” and “2 = Need to be very careful”.\nYour data editor window should look something like this:\n\n\n\n\n\n\nQuestion\nThe variable measurement level (Column type) appears as Ordinal. Is that correct? If you feel that the variable type should be changed, you can also do that here using the drop-down menu next to Column type.\n\nTo return to your data analysis, you can click on the Analyses menu tab. If you have changed the variable’s name, you can move it back to the Variables field to see the updated outputs.\n\nFind the other variables in the dataset that relate to social, interpersonal or institutional trust, and obtain similar descriptive statistics for them. Try to answer to yourself the same questions as above.\nAdd your notes to the Results output. By clicking on the small black down-arrowheads that appear next to the headings in the Results window when you hover over them with your mouse you can access small menu options that allow you to do various operations with the outputs (copy, save, edit, etc.), including the possibility to Add note. Your note will appear under the item to which it is added, and you can type in your note. The field acts as a basic text editor, which you can use to jot down your interpretation of the results and keep them close to the output. You can add in here your answers to some of the questions above.\n\nYour results and notes could look something like this (based on the WVS7 dataset for Andorra):\n\n\n\n\n\n\nSave your analysis. Click through Hamburger menu tab &gt; Save as &gt; Computer &gt; Browse and save the analysis in your “WVS7” folder with the name “wvs7-example.jasp” (or anything else that you find useful). Once it’s saved, you can close the analysis. You can now open the .jasp file you saved and continue or modify the analysis you have started.\n\n\n\n\n\n\n\nTip\n\n\n\nFor simplicity we have downloaded the dataset in CSV format, which is a simple plain text format that can be opened with text editors or spreadsheet tools such as Microsoft Excel. However, some other formats that belong to proprietary statistical software packages like SPSS or Stata are likely to store more information (e.g. variable and value label, etc.), and downloading the data in that format and importing it to JASP may make it easier to explore the data without needing to do too many manual changes.\nYou can experiment by downloading the data in another format (Stata appears to be the most stable for importing to JASP) and checking the data editor window.\n\n\n\nNow open a new JASP session and import the “ESS10” dataset you downloaded earlier, and perform a similar descriptive analysis on variables related to social, interpersonal and institutional trust you have done above. When complete, save that analysis to a .jasp file too.\n\n\n\n\nBelow are some research questions that you can choose from to address in Assignment 1:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?\n\nFor now, choose one question that you find most sympathetic (you don’t need to stick with it for the assignment, but you could if you wanted to!). All of the questions can be answered with at least one of the survey datasets that you downloaded (the “WVS7” or “ESS10”) and often they both contain relevant variables.\n\nIdentify your “explanandum” - i.e. the core phenomenon/concept/behaviour/etc. that the research question aims to explain. The questions all postulate a relationship/association between two or more variables (the topic of the next workshop), but for now, think carefully about the question and how it is formulated, and identify which is the variable that will be the target of explanation, and which variable (if mentioned) will be used for explaining it. For example, in the research question “Does education increase social trust?”, the variable we are interested in explaining is “social trust”, while “education” is the variable that we will use to explain it. In later workshops we will develop better vocabulary to describe associations between variables.\nOnce the core phenomenon to be explained is identified, look through the two survey questionnaires to identify any variables that might exist in the dataset that captures it. This may require some trial-and-error with testing out search words.\nOnce you have found one (or several) candidate variable(s), navigate to the relevant survey website and select a single country for which to download data. You will be working with single-country datasets for your assignment. Download the dataset, import it into JASP, find the relevant variable and perform some descriptive analysis on the chosen variable as you have done in the previous exercise.\nMake sure to add your noted and interpretations on the analysis results and save your analysis for later. You could create a new sub-folder for your “Assignment 1” work and save your analysis there for future use. If you end up liking your chosen question, you can continue this analysis in the next workshop."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w1.html#learning-outcomes",
    "href": "Materials/Worksheets/draft_worksheet_w1.html#learning-outcomes",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "By the end of the session you will have gained familiarity with:\n\nsome important cross-national survey programmes\nhow to find, download and read data documentation, including survey questionnaires\nthe challenges of measuring sociological concepts\nthe JASP interface"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w1.html#intro",
    "href": "Materials/Worksheets/draft_worksheet_w1.html#intro",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "The lecture has introduced the complexities of measuring sociological concepts. Throughout this short course, we will be using the measurement and estimation of social trust as a guiding example. However, the aim is to help you build up your skills and confidence in asking and addressing research questions of your own, and the assessment questions will ask you to analyse some other chosen research topic.\nIn this first workshop, you will begin your data analysis journey by exploring some online sources of cross-national sociological data available for secondary analysis, and you will practice performing basic descriptive analyses of selected variables."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w1.html#exercise-0-create-a-folder-structure-for-this-module",
    "href": "Materials/Worksheets/draft_worksheet_w1.html#exercise-0-create-a-folder-structure-for-this-module",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "Create a folder for this module on your institutional OneDrive (e.g. C:\\OneDrive - Newcastle University\\SOC2069). Within that folder, create a sub-folder called “Data”. You will then be able to save data files and documentation as you progress."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w1.html#exercise-1-explore-the-world-values-survey-data-documentation",
    "href": "Materials/Worksheets/draft_worksheet_w1.html#exercise-1-explore-the-world-values-survey-data-documentation",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "About 20 minutes\n\nNavigate to the The World Values Survey (WVS) website and read about the World Values Survey.\n\n\nDon’t spend too much time browsing the website, but make sure you can answer the following questions:\n\nWhen was the WVS started, and how many waves of data collection have there been so far?\nIn which year(s) did the most recent wave of data collection take place?\nHow many countries were covered by the most recent wave?\nCan you name some of the topics covered by the WVS?\nWhat population are the national samples representative of?\nWhat is the general minimum sample size per country?\nIs the WVS data freely available for academic research purposes?\nDo you need to cite/reference the WVS data if you use it in your research?\nBonus: what is the difference between a time series dataset and a panel dataset, and which of the two can the WVS provide? (tip: look under Data and Documentation &gt; Data Download &gt; Timeseries (1981-2022) for a concise discussion)\n\n\n\nNavigate to Data and Documentation &gt; Data Download &gt; Wave 7 (2017-2022) page and explore the Questionnaire and Documentation. Download the Master Questionnaire and the Codebook documents and using the search function identify all the survey questions and variables that relate to “trust”.\n\n\nQuestions\n\nHow many questions relating to trust have you identified in the questionnaires?\nWhat is the difference between the questionnaire and the codebook?\nIn how many different ways is trust measured in the WVS?\nWhat are, in your opinion, the advantages and disadvantages of the different measurements of trust?\n\n\n\nWithin the “Data” sub-folder you created earlier, create another sub-folder called “WVS7”. You can now save the Master Questionnaire and the Codebook into that folder, and because it is stored on the institutional OneDrive, you will always have access to it on any computer, once you log in to your institutional Microsoft Windows account.\nIn the Select a country panel on the right side of the Wave 7 (2017-2022) page select one country at random and under Data files download the country-specific dataset (for consistency, download the first data type option, CSV (i.e. comma separated values)) to the “WVS7” subfolder you created earlier."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w1.html#exercise-2-explore-the-european-social-survey-data-documentation",
    "href": "Materials/Worksheets/draft_worksheet_w1.html#exercise-2-explore-the-european-social-survey-data-documentation",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "About 20 minutes\nLet’s now navigate to The European Social Survey (ESS) and read about the survey. Try to answer to yourself the same questions as in the previous exercise\n\nNavigate to Data and then to the ESS Data Portal &gt; ESS Round 10 - 2020 &gt; ESS10 - Study Documentation. Download the ESS10 Source questionnaires to a newly created sub-folder called “ESS10”, and as in the previous exercise, identify all the survey questions and variables that relate to “trust”.\nNavigate to ESS Data Portal &gt; Datafile Builder (Wizard) and select one country at random at Round 10 (or 10SC). Keep all the variables (do not select any subsets in the “Select Variables” tab) and download the country-specific dataset in CSV format to your “ESS10” folder.\n\n\n\n\n\n\n\nNote\n\n\n\nTo be able to download data, you will need to register with the European Social Survey. Complete the registration before you can proceed\n\n\nYou now have a large amount of data at your fingertips. After a break, we will explore these data using a statistical software package"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w1.html#exercise-3-describing-trust-using-jasp",
    "href": "Materials/Worksheets/draft_worksheet_w1.html#exercise-3-describing-trust-using-jasp",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "About 30 minutes\nOpen the JASP software from the Start menu. If you are using your own laptop, you can install the latest version of JASP from https://jasp-stats.org/.\nThe opening page should look something like this:\n\n\n\n\n\nTo open a dataset stored on your computer, you can navigate to the three horizontal bars (“hamburger”) menu icon &gt; Open &gt; Computer &gt; Browse.\n\n\n\n\n\n\nNote\n\n\n\nTo be able to see and load the data you downloaded from the WVS and ESS, you need to first extract the files from the compressed folder. Navigate to your Data folder outside the JASP data import window and extract your files, then return to the JASP window to open one of them.\n\n\n\nOpen the “WVS7” dataset. You should now see something like this:\n\n\n\n\n\n\nYou can scroll up-down and left-right in the dataset to have a look at the spreadsheet and its contents.\nIn JASP you can work on one dataset at a time (or in one window). When you finish your analysis, you can save both the data and the outputs you generated as one .jasp file, which you can then open later and continue or alter your analyses.\nToday, we will explore some descriptive statistics using the Descriptives &gt; Descriptive Statistics menu option. If you click through, you should see something like this:\n\n\n\n\n\n\nUsing the survey questionnaire, identify the variable coding “social/generalised trust” and move that variable to the Variables field\nApart from the default Descriptive Statistics table, select Basic plots &gt; Distribution plots as well and interpret the distribution of the variable in your dataset\n\n\nQuestions\n\nHow many levels (categories) does the variable have in your dataset? is it what you had expected based on the questionnaire information?\nDoes the variables have any missing values in your dataset?\nWhat is the “Mode” of the variable, and what does that mean?\nWhat is the “Mean” of the variable, and what does that mean? Is it a useful statistic for this variable?\nWhat percentage of the respondents in your dataset had answered that “Most people can be trusted”?\n\n\n\n\n\n\n\n\nSolution\n\n\n\nUsing the WVS7 dataset for the United Kingdom, and having identified the “social trust” variable from the Questionnaire and/or Codebook to be named “Q57” in the dataset, we obtain the following descriptive statistics:\n\n\n\n\n\n\nThere appear to be 3 levels in the variables. Form the questionnaire we know that there should be 2 valid categories only: 1 (Most people can be trusted) and 2 (Need to be very careful);\nFrom the Codebook we know that there may be some other values coded by the researchers as well: -1 for “Don´t know”, -2 for “No answer”, -4 for “Not asked” and -5 for “Missing”. These are coded with negative values in order to stand out as non-standard categories of answers. They code various reasons for why values may be “missing” in the dataset. In the UK dataset we are using here we have three of these values present;\nBy looking at the distribution plot, we see that the tallest bar (the largest answer category) is the one coded as 2. The largest (most common) category of a categorical variables is called the “mode”. We can also request for the “mode” the “median” and other potentially informative summary statistics to also be included in the Descriptive Statistics table by ticking the appropriate boxes under the Statistics option-bar in the Descriptive Statistics builder on the left hand side:\n\n\n\nAccording to the Descriptive Statistics table the mean of the variable is 1.488. However, in this case this is not a sensible statistic. First of all, we have a categorical variable, so an average value between 1 (Most people can be trusted) and 2 (Need to be very careful) does not mean much. If anything, in the case of only two categories, we know that if category 1 and category 2 are of equal size (i.e. the same number of people have answered each of them), then the mean would be \\({1 + 2 \\over 2} = 1.5\\), so a mean of 1.48 would indicate that the category coded as 1 is slightly larger. However, secondly, in our case we also have the several negative values that are also added up in the calculation of the mean. Under these circumstances, the mean cannot tell us anything accurate or useful.\nTo get a more precise percentage of the distribution of the answer options (categories) across the variable, we would need to request a Frequency table in the Descriptive Statistics builder, which we can do under the Tables option-bar:\n\nThe result would be:\n\nWe therefore find that almost 46% of the respondents in the dataset had answered that “Most people can be trusted”. However, this also counts with all the “missing” responses. If we would like to get a more accurate values for the “Valid Percent” (i.e. the percentage distribution among only those with valid response options, 1 or 2), then we will need to tell JASP to consider the negative values as “missing”.\n\n\n\nIf you see more than two levels/categories in your variable (and you are sure that you have chosen the correct variable), it means that in your dataset the variable contains some custom missing values. Missing values should be distinguished with a negative sign (e.g. -2). To set them as custom missing values, we can edit the dataset manually.\n\nClick on the Edit Data menu tab and scroll horizontally to your variable. Double-click on the variable column. In the middle tabs, check the label editor and identify any values that should be set as missing (e.g. -2). Click on the Missing values tab &gt; Use custom values and in the narrow field to the right type in the value you want to set as missing and click the + sign. You should be seeing something like below:\n\n\n\n\n\n\nYou can check back in the Label editor that the redundant value is not longer there.\n\nIn the same data editor window we can also make other changes to our variables. For example, let’s change the non-informative variable Name to something that better reflects the meaning of the variable, for example “soc-trust”, and let’s also give it a more descriptive Long name and even a Description if we want to. The Long name could be something like “Social trust”, and for the Description we could copy the original survey question out from the questionnaire: “Q57. Generally speaking, would you say that most people can be trusted or that you need to be very careful in dealing with people?”.\n\nIn the Label editor we should also attach labels to the values so that we can better read the outputs produced. We can copy the labels from the questionnaire here too: “1 = Most people can be trusted” and “2 = Need to be very careful”.\nYour data editor window should look something like this:\n\n\n\n\n\n\nQuestion\nThe variable measurement level (Column type) appears as Ordinal. Is that correct? If you feel that the variable type should be changed, you can also do that here using the drop-down menu next to Column type.\n\nTo return to your data analysis, you can click on the Analyses menu tab. If you have changed the variable’s name, you can move it back to the Variables field to see the updated outputs.\n\nFind the other variables in the dataset that relate to social, interpersonal or institutional trust, and obtain similar descriptive statistics for them. Try to answer to yourself the same questions as above.\nAdd your notes to the Results output. By clicking on the small black down-arrowheads that appear next to the headings in the Results window when you hover over them with your mouse you can access small menu options that allow you to do various operations with the outputs (copy, save, edit, etc.), including the possibility to Add note. Your note will appear under the item to which it is added, and you can type in your note. The field acts as a basic text editor, which you can use to jot down your interpretation of the results and keep them close to the output. You can add in here your answers to some of the questions above.\n\nYour results and notes could look something like this (based on the WVS7 dataset for Andorra):\n\n\n\n\n\n\nSave your analysis. Click through Hamburger menu tab &gt; Save as &gt; Computer &gt; Browse and save the analysis in your “WVS7” folder with the name “wvs7-example.jasp” (or anything else that you find useful). Once it’s saved, you can close the analysis. You can now open the .jasp file you saved and continue or modify the analysis you have started.\n\n\n\n\n\n\n\nTip\n\n\n\nFor simplicity we have downloaded the dataset in CSV format, which is a simple plain text format that can be opened with text editors or spreadsheet tools such as Microsoft Excel. However, some other formats that belong to proprietary statistical software packages like SPSS or Stata are likely to store more information (e.g. variable and value label, etc.), and downloading the data in that format and importing it to JASP may make it easier to explore the data without needing to do too many manual changes.\nYou can experiment by downloading the data in another format (Stata appears to be the most stable for importing to JASP) and checking the data editor window.\n\n\n\nNow open a new JASP session and import the “ESS10” dataset you downloaded earlier, and perform a similar descriptive analysis on variables related to social, interpersonal and institutional trust you have done above. When complete, save that analysis to a .jasp file too."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w1.html#exercise-4-begin-your-analysis-for-assignment-1",
    "href": "Materials/Worksheets/draft_worksheet_w1.html#exercise-4-begin-your-analysis-for-assignment-1",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "Below are some research questions that you can choose from to address in Assignment 1:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?\n\nFor now, choose one question that you find most sympathetic (you don’t need to stick with it for the assignment, but you could if you wanted to!). All of the questions can be answered with at least one of the survey datasets that you downloaded (the “WVS7” or “ESS10”) and often they both contain relevant variables.\n\nIdentify your “explanandum” - i.e. the core phenomenon/concept/behaviour/etc. that the research question aims to explain. The questions all postulate a relationship/association between two or more variables (the topic of the next workshop), but for now, think carefully about the question and how it is formulated, and identify which is the variable that will be the target of explanation, and which variable (if mentioned) will be used for explaining it. For example, in the research question “Does education increase social trust?”, the variable we are interested in explaining is “social trust”, while “education” is the variable that we will use to explain it. In later workshops we will develop better vocabulary to describe associations between variables.\nOnce the core phenomenon to be explained is identified, look through the two survey questionnaires to identify any variables that might exist in the dataset that captures it. This may require some trial-and-error with testing out search words.\nOnce you have found one (or several) candidate variable(s), navigate to the relevant survey website and select a single country for which to download data. You will be working with single-country datasets for your assignment. Download the dataset, import it into JASP, find the relevant variable and perform some descriptive analysis on the chosen variable as you have done in the previous exercise.\nMake sure to add your noted and interpretations on the analysis results and save your analysis for later. You could create a new sub-folder for your “Assignment 1” work and save your analysis there for future use. If you end up liking your chosen question, you can continue this analysis in the next workshop."
  },
  {
    "objectID": "Materials/Info/info_w4.html",
    "href": "Materials/Info/info_w4.html",
    "title": "Modelling dichotomous outcomes",
    "section": "",
    "text": "In the social sciences we are often confronted with phenomena and concepts measured not on a numeric scale but on a categorical scale. Linear regression analysis has provided us with a general approach which can be generalised to categorical dependent variables, but this generalisation relies on a mathematical transformation of the dependent variable using the natural logarithm. Luckily, we have powerful software to take care of these transformations for us, and we can instead focus on understanding the sociological importance of estimating the probability of cases (people) with certain characteristics to belong to one outcome category as opposed to another.  We will focus on the basic case where there are only two (dichotomous, binary) outcome categories, which can be modelled using logistic regression, another versatile and foundational statistical method that is probably the most commonly employed in sociological research.\n\n\n(Access links through Canvas - Newcastle University login required)\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 5 | Modelling Relationships Using Regression (reading from section Different Types of Response Variable)\nCHAPTER 6 | Algorithms, Analytics and Prediction\nCHAPTER 8 | Probability – the Language of Uncertainty and Variability\n\nGoss-Sampson (2025) Statistical Analysis in JASP:\n\nLOGISTIC REGRESSION (pp. 88-92)\n\n\nApplication:\n\nDelhey, Jan, and Kenneth Newton (2003) “Who Trusts?: The Origins of Social Trust in Seven Societies.” European Societies 5(2): 93–137.\n\n\n\n\nStatistics:\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 9 (“Logistic regression”)\n\nConnelly, Roxanne, Vernon Gayle, and Paul S. Lambert (2016) “Statistical Modelling of Key Variables in Social Survey Data Analysis”. Methodological Innovations9:205979911663800.\n\nAdvanced topics:\n\nMood, Carina (2010) “Logistic Regression: Why We Cannot Do What We Think We Can Do, and What We Can Do About It.” European Sociological Review 26(1): 67–82.\nBreen, Richard, Kristian Bernt Karlson, and Anders Holm (2018) “Interpreting and Understanding Logits, Probits, and Other Nonlinear Probability Models.” Annual Review of Sociology 44(1): 39–54.\n\n\n\n\n\n Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 4",
      "[W4] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w4.html#readings",
    "href": "Materials/Info/info_w4.html#readings",
    "title": "Modelling dichotomous outcomes",
    "section": "",
    "text": "Statistics:\n\nIMS: Chapter 9 (“Logistic regression”)\nConnelly, Roxanne, Vernon Gayle, and Paul S. Lambert. 2016. “Statistical Modelling of Key Variables in Social Survey Data Analysis”. Methodological Innovations9:205979911663800.\n\nNCL Library Link\n\n\nApplication:\n\nDelhey, Jan, and Kenneth Newton.\n\n“Who Trusts?: The Origins of Social Trust in Seven Societies.” European Societies 5(2): 93–137.\n\n\nNCL Library Link\nDownload PDF: Delhey & Newton (2003) Who trusts\n\n\nAdvanced topics:\n\nMood, Carina.\n\n“Logistic Regression: Why We Cannot Do What We Think We Can Do, and What We Can Do About It.” European Sociological Review 26(1): 67–82.\n\n\nNCL Library Link\n\nBreen, Richard, Kristian Bernt Karlson, and Anders Holm.\n\n“Interpreting and Understanding Logits, Probits, and Other Nonlinear Probability Models.” Annual Review of Sociology 44(1): 39–54.\n\n\nNCL Library Link",
    "crumbs": [
      "Materials",
      "Workshop 4",
      "[W4] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w4.html#lecture-slides",
    "href": "Materials/Info/info_w4.html#lecture-slides",
    "title": "Modelling dichotomous outcomes",
    "section": "",
    "text": "Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 4",
      "[W4] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w2.html",
    "href": "Materials/Info/info_w2.html",
    "title": "Comparisons and Associations",
    "section": "",
    "text": "Drawing comparisons and identifying associations between variables underpins most quantitative sociological analyses. While in Workshop 1 we practiced describing variables individually, we now focus on describing variables in relation to one another. We make further steps in understanding the concept of “social trust” by exploring various factors that appear associated with it. Identifying associations and patterns in a dataset, and setting up new research hypothesis based on them is often the most that we can realistically do with our data.\nMost often than not, however, our true aim is to set up a statistical model that can be used for making predictions or testing causal relationships about our phenomenon of interest. We will explore these aims and their limits over the next two workshops in exploring how we can make more directed comparisons and identify cleaner associations using regression techniques.\n\n\n(Access links through Canvas - Newcastle University login required)\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 2 | Summarizing and Communicating Numbers. Lots of Numbers (continue reading from the section on Describing Relationships Between Variables)\nCHAPTER 4 | What Causes What?\nCHAPTER 3 | Why Are We Looking at Data Anyway? Populations and Measurement (recommended now, essential by Workshop 5)\n\nGoss-Sampson (2025) Statistical Analysis in JASP:\n\nDESCRIPTIVE DATA VISUALISATION (pp. 21-30)\nEXPLORING DATA INTEGRITY (pp. 30-37)\nDATA TRANSFORMATION (pp. 38-41)\nCOMPARING TWO INDEPENDENT GROUPS (pp. 56-63)\nCOMPARING TWO RELATED GROUPS (pp. 63-69)\nCORRELATION ANALYSIS (pp. 69-75)\nCHI-SQUARE TEST FOR ASSOCIATION (pp. 145-152)\n\n\nApplication:\n\nChapter 4 (“Community life and social relations”, pp. 49-62) in Wilkinson and Pickett (2010) The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press.\nDelhey, Jan, and Kenneth Newton. 2005. “Predicting Cross-National Levels of Social Trust: Global Pattern or Nordic Exceptionalism?” European Sociological Review 21(4): 311–27.\n\n\n\n\nStatistics:\n\nKranzler (2022) Statistics for the Terrified:\n\nChapter 9 (“The t Test”)\nChapter 10 (“Analysis of Variance”)\nChapter 11 (“Correlation Coefficients”)\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 4 (“Exploring categorical data”)\nChapter 5 (“Exploring numerical data”)\n\n\nSubstantive:\n\nDinesen, Peter Thisted, and René Bekkers. 2017. “The Foundations of Individuals’ Generalized Social Trust: A Review.” Pp. 77–100 in Trust in Social Dilemmas, edited by P. A. M. van Lange, B. Rockenbach, and T. Yamagishi. New York, NY: Oxford University Press.\n\n\n\n\n\n Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 2",
      "[W2] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w2.html#readings",
    "href": "Materials/Info/info_w2.html#readings",
    "title": "Comparisons and Associations",
    "section": "",
    "text": "Statistics:\n\nIMS: Chapters 4 (“Exploring categorical data”) and 5 (“Exploring numerical data”)\n\nApplication:\n\nChapter 4 (“Community life and social relations”, pp. 49-62) in Wilkinson, Richard G., and Kate Pickett. 2010. The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press.\nDelhey, Jan, and Kenneth Newton. 2005. “Predicting Cross-National Levels of Social Trust: Global Pattern or Nordic Exceptionalism?” European Sociological Review 21(4): 311–27\n\nFurther reading:\n\nDinesen, Peter Thisted, and René Bekkers. 2017. “The Foundations of Individuals’ Generalized Social Trust: A Review.” Pp. 77–100 in Trust in Social Dilemmas, edited by P. A. M. van Lange, B. Rockenbach, and T. Yamagishi. New York, NY: Oxford University Press.",
    "crumbs": [
      "Materials",
      "Workshop 2",
      "[W2] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w2.html#lecture-slides",
    "href": "Materials/Info/info_w2.html#lecture-slides",
    "title": "Comparisons and Associations",
    "section": "",
    "text": "Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 2",
      "[W2] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w0.html",
    "href": "Materials/Info/info_w0.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to the module! This introductory lecture provides an overview of both components - quantitative and qualitative research methods - of the module. The slides below focus specifically on the quantitative component to which this website is dedicated.\n\n\nThis is an embedded &lt;a target=\"_blank\" href=\"https://office.com\"&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=\"_blank\" href=\"https://office.com/webapps\"&gt;Office&lt;/a&gt;.\n Download the slides",
    "crumbs": [
      "Materials",
      "Introduction",
      "Introduction"
    ]
  },
  {
    "objectID": "Materials/Info/info_w0.html#lecture-slides",
    "href": "Materials/Info/info_w0.html#lecture-slides",
    "title": "Introduction",
    "section": "",
    "text": "This is an embedded &lt;a target=\"_blank\" href=\"https://office.com\"&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=\"_blank\" href=\"https://office.com/webapps\"&gt;Office&lt;/a&gt;.\n Download the slides",
    "crumbs": [
      "Materials",
      "Introduction",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "SOC2069 (Researching Social Life) is a 2nd-year undergraduate module (i.e. course) for Sociology and Politics and Sociology students at Newcastle University (UK). The module consists of two parts: one one quantitative methods and one on qualitative methods. This site hosts materials pertaining to the quantitative methods part of the module delivered over five weeks in the Autumn semester."
  },
  {
    "objectID": "Data/index.html",
    "href": "Data/index.html",
    "title": "Quantitative Datasets",
    "section": "",
    "text": "Workshop data\n\n\n\n\n\n\n Questions of Trust\n\n\n\n\n\nThis is a collection of six small datasets compiled from original sources to exemplify several different ways in which the “social trust” / “generalised trust” question has been asked in social surveys. The datasets are helpful for thinking through questions about concept measurement similar to those asked by Bekkers and Sandberg (2019).\nThe focus of the datasets is on a single country: Great Britain / United Kingdom. The original datasets have been reduced to a small number of variables: (1) respondent ID number; (2) questionnaire subsample (if relevant and available); (3) age (both numeric and categorical (7 categories) where available); (4) sex; (5) and social trust. The order of the variables in the dataset, variable names and labels, and value/category codes and labels - including missing values - were left as in the original surveys (the only exception is the gb-cls23-trust_nm dataset, where the missing values have been excluded due to the large size of the original file - over 100,000 rows - which cannot be opened by JASP). The datasets can be downloaded in .sav (SPSS) format and loaded directly in JASP or R.\nThe available datasets and their original sources are:\n\nBritish Social Attitudes Survey 2024 (gb-bsa24-trust.sav)\nBritish Social Attitudes Survey 2023 (gb-bsa23-trust.sav)\nBritish Social Attitudes Survey 2010 (gb-bsa10-trust.sav)\nCommunity Life Survey 2023-24 (gb-cls23-trust_nm.sav)\nCitizenship Survey 2010-11 (gb-cs10-trust.sav)\nEuropean Social Survey, Round 11, 2023-24 (UK sample) (gb-ess11-trust.sav)\n\n\n Download\n\n\n\nBritish Social Attitudes Survey 2024\n\n\nBritish Social Attitudes Survey 2023\n\n\nBritish Social Attitudes Survey 2010\n\n\nCommunity Life Survey 2023-24\n\n\nCitizenship Survey 2010-11\n\n\nEuropean Social Survey 11, 2023-24\n\n\n\n\n\n\n\n\n\n\n\n Trust & Inequality   |   trust_inequality.dta\n\n\n\n\n\nThis dataset combines data on “generalised/social trust” from the latest waves of the World Values Survey and the European Values Study with macro(country)-level data on World Development Indicators (WDI) provided by the World Bank. The main variables of interest taken from the WDI refer to measurements of economic inequality within countries. The dataset allows us to conceptually replicate - using the latest available data - the analysis of the relationship between inequality and trust presented in Chapter 4 (“Community life and social relations”, pp. 49-62) of Wilkinson and Pickett (2010).\n Download\n\n\n\n\n\n\n\n\n\n Österman, Table 3   |   osterman_t3.dta\n\n\n\n\n\nThis dataset is the one used by Österman (2021) for the analysis underpinning the results reported in his Table 3 and related tables in the Online Supplementary Material. The aim of the article is to use information on educational reforms across European countries as a way to set up a quasi-experimental design testing the effect of education on social trust. With this approach, it aims to overcome the limitations of cross-sectional observational survey data from the European Social Survey by attempting a causal - rather than just correlational- explanation.\n Download\n\n\n\n\n\n\n\n\n\n Delhey & Newton, 2003   |   delhey&newton2003.sav\n\n\n\n\n\nThis dataset contains data from the EUROMODULE (1999-2002) surveys conducted in nine countries: Germany (DE) | Austria (AT) | Switzerland (CH) | Sweden (SE) | Spain (ES) | Slovenia (SI) | Korea, Republic of (KR) | Turkey (TR) | Hungary (HU). Out of the total of 366 variables measured, only those 100 were kept in this dataset that were used by Delhey and Newton (2003) in their analysis of the various correlates of “social trust”. The value of the EUROMODULE survey data compared to other comparative surveys that measure social trust is that it offers a much greater variety of explanatory variables that allow Delhey and Newton (2003) to test the relative explanatory power of several complex social theories explaining differences in levels of social trust both at the individual level and at the macro-social level.\n Download   Original questionnaire    Original Codebook    Data wrangling code (.R) \n\n\n\n\n\n\n\n\n\n Data transformation   |   data_transformation.jasp\n\n\n\n\n\nThis is a toy dataset derived from the European Social Survey, Round 10 (ESS10). Its aim is to be used to demonstrate several basic data transformation procedures in JASP. It contains 15 cases/observations/rows and 12 variables/features/columns (in addition to a Respondent ID variable). The cases were selected so as to include some missing values and reasonable variation across the selected variables.\nThe dataset should be used in conjunction with the ESS10 Questionnaire and Codebook.\nThis dataset is used in some of the data management example short videos available on this JASP tutorial YouTube playlist.\n Download\n\n\n\n\n\nAssignment data\nYou will use one of the datasets available below for your assignment task. These are real-life data from large-scale nationally representative surveys that include variables relating to the research questions posted on Canvas. To make the data more manageable (and because the module cannot cover some very important but more advanced topics such as clustering standard errors and multi-level modelling of cross-country data, or applying survey weights) the datasets are broken down by country and contain only a small selection of the variables available from the original surveys.\n\n\n\n\n\n\n World Values Survey, Wave 7   |   wvs7_XXX.sav\n\n\n\n\n\nThe World Values Survey (WVS) is an international research program devoted to the scientific and academic study of social, political, economic, religious and cultural values of people in the world. The project grew out of the European Values Study and was started in 1981. Since then it has been operating in more than 120 world societies. The main research instrument of the project is a representative comparative social survey which is conducted globally every 5 years. The datasets below come from Wave 7 (2017-2022) data, which comprised 66 countries/territories. The majority of surveys were completed in 2018-2020 with only about a dozen countries conducting their fieldwork since the Covid-19 pandemic outbreak in 2021-2022. The last included survey comes from India and was completed in July 2023.\nYou should cite the original data source in your assignments as:\n\nHaerpfer, C., Inglehart, R., Moreno, A., Welzel, C., Kizilova, K., Diez-Medrano J., M. Lagos, P. Norris, E. Ponarin & B. Puranen (eds.) (2022). World Values Survey: Round Seven. Datafile Version 5.0. Madrid, Spain & Vienna, Austria: JD Systems Institute & WVSA Secretariat. doi:10.14281/18241.24\n\n\n Download (single-country)\n\n\n\nAndorra\n\n\nArgentina\n\n\nArmenia\n\n\nAustralia\n\n\nBangladesh\n\n\nBolivia\n\n\nBrazil\n\n\nCanada\n\n\nChile\n\n\nChina\n\n\nColombia\n\n\nCyprus\n\n\nCzechia\n\n\nGermany\n\n\nEcuador\n\n\nEgypt\n\n\nEthiopia\n\n\n\nGreece\n\n\nGuatemala\n\n\nHong Kong SAR\n\n\nIndonesia\n\n\nIndia\n\n\nIran\n\n\nIraq\n\n\nJordan\n\n\nJapan\n\n\nKazakhstan\n\n\nKenya\n\n\nKyrgyzstan\n\n\nSouth Korea\n\n\nLebanon\n\n\nLibya\n\n\nMacau SAR\n\n\nMorocco\n\n\nMaldives\n\n\nMexico\n\n\nMyanmar\n\n\nMongolia\n\n\nMalaysia\n\n\nNigeria\n\n\nNicaragua\n\n\nNetherlands\n\n\nNew Zealand\n\n\nPakistan\n\n\nPeru\n\n\nPhilippines\n\n\nPuerto Rico\n\n\nRomania\n\n\nRussia\n\n\nSingapore\n\n\nSerbia\n\n\nSlovakia\n\n\nThailand\n\n\nTajikistan\n\n\nTunisia\n\n\nTurkey\n\n\nTaiwan ROC\n\n\nUkraine\n\n\nUruguay\n\n\nUnited States\n\n\nUzbekistan\n\n\nVenezuela\n\n\nVietnam\n\n\nZimbabwe\n\n\n\n Original questionnaire\n\n\n Original Codebook\n\n\n Data wrangling code (.R)\n\n\n\n\n\n\n\n\n\n\n European Values Study, 2017   |   evs2017_XXX.sav\n\n\n\n\n\nThe European Values Study (EVS) is a large-scale, cross-national and longitudinal survey research program on how Europeans think about family, work, religion, politics, and society. Repeated every nine years in an increasing number of countries, the survey provides insights into the ideas, beliefs, preferences, attitudes, values, and opinions of citizens all over Europe. The latest (fifth) wave of the survey, EVS 2017, was conducted in 37 participating countries.\nYou should cite the original data source in your assignments as:\n\nEVS (2022). European Values Study 2017: Integrated Dataset (EVS 2017). GESIS, Cologne. ZA7500 Data file Version 5.0.0, https://doi.org/10.4232/1.13897.\n\n\n Download (single-country)\n\n\n\nAlbania\n\n\nAzerbaijan\n\n\nAustria\n\n\nArmenia\n\n\nBosnia and Herzegovina\n\n\nBulgaria\n\n\nBelarus\n\n\nCroatia\n\n\nCzechia\n\n\nDenmark\n\n\nEstonia\n\n\nFinland\n\n\nFrance\n\n\nGeorgia\n\n\nGermany\n\n\nHungary\n\n\nIceland\n\n\nItaly\n\n\nLatvia\n\n\nLithuania\n\n\nMontenegro\n\n\nNetherlands\n\n\nNorway\n\n\nPoland\n\n\nPortugal\n\n\nRomania\n\n\nRussia\n\n\nSerbia\n\n\nSlovakia\n\n\nSlovenia\n\n\nSpain\n\n\nSweden\n\n\nSwitzerland\n\n\nUkraine\n\n\nNorth Macedonia\n\n\n\n\n Original questionnaire\n\n\n Original Codebook\n\n\n Data wrangling code (.R)\n\n\n\n\n\n\n\n\n\n\n European Social Survey, 10   |   ess10_XXX.sav\n\n\n\n\n\nThe European Social Survey (ESS) is an academically driven cross-national survey that has been conducted across Europe since 2001. Every two years, face-to-face interviews are conducted with newly selected, cross-sectional samples.The survey measures the attitudes, beliefs and behaviour patterns of diverse populations and has been administered in 40 countries to date. ESS data collection is based on an hour-long face-to-face interview. The tenth ESS round covers 31 countries.\nYou should cite the original data source in your assignments as:\n\nEuropean Social Survey European Research Infrastructure (ESS ERIC) (2023). ESS10 integrated file, edition 3.2 [Data set]. Sikt - Norwegian Agency for Shared Services in Education and Research. https://doi.org/10.21338/ess10e03_2\n\n\n Download (single-country)\n\n\n\nBelgium\n\n\nBulgaria\n\n\nSwitzerland\n\n\nCzechia\n\n\nEstonia\n\n\nFinland\n\n\nFrance\n\n\n\nGreece\n\n\nCroatia\n\n\nHungary\n\n\nIreland\n\n\nIceland\n\n\nItaly\n\n\nLithuania\n\n\nMontenegro\n\n\nNorth Macedonia\n\n\nNetherlands\n\n\nNorway\n\n\nPortugal\n\n\nSlovenia\n\n\nSlovakia\n\n\n\n Original questionnaire\n\n\n Original Codebook\n\n\n Data wrangling code (.R)\n\n\n\n\n\n\n\n\n\n\n Variable search\n\n\n\n\n\nUse the search table below to quickly check what variables are available in which survey dataset. In the Search field you can search for any keyword; in the Show [ ] entries field you can select to display more/all variables:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nBekkers R and Sandberg B (2019) Grading Generalized Trust Across Europe. In: André S, Kraaykamp G, Meuleman R, et al. (eds.) Samenhang in Europa: Eenheid in Verscheidenheid. Proceedings Zesde Nederlandse Workshop European Social Survey. The Hague, pp. 97–119. Available at: https://osf.io/c9mq4/ (accessed 19 February 2024).\n\n\nDelhey J and Newton K (2003) Who trusts?: The origins of social trust in seven societies. European Societies 5(2). Routledge: 93–137.\n\n\nÖsterman M (2021) Can we trust education for fostering trust? Quasi-experimental evidence on the effect of education and tracking on social trust. Social Indicators Research 154(1): 211–233.\n\n\nWilkinson RG and Pickett K (2010) The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press."
  },
  {
    "objectID": "Materials/index.html",
    "href": "Materials/index.html",
    "title": "",
    "section": "",
    "text": "Workshop\nTopic\nInfo\nNotes\nSlides\nWorksheets\n\n\n\n\n\nSoftware\n\n\n  \n\n\n\n\nIntroduction: Statistics, data and models\n\n\n  \n\n\n\nWorkshop 1\nMeasurement and Description\n\n  \n  \n  \n\n\nWorkshop 2\nComparisons and Associations\n\n  \n  \n  \n\n\nWorkshop 3\nModelling continuous outcomes\n\n  \n  \n  \n\n\nWorkshop 4\nModelling binary outcomes\n\n  \n  \n  \n\n\nWorkshop 5\nUncertainty and Inference",
    "crumbs": [
      "Materials",
      "Outline and materials"
    ]
  },
  {
    "objectID": "Materials/Info/info_w1.html",
    "href": "Materials/Info/info_w1.html",
    "title": "Measurement and Description",
    "section": "",
    "text": "We begin our exploration of quantitative methods in sociology (and the social sciences more broadly) by thinking carefully about how we make the passage from theory and concepts to empirical data. For concepts to be explored empirically (not just theoretically), we need to operationalise them. The lecture introduces some core ideas behind social measurement in general. In the IT workshop, we will look more carefully at examples of how “social trust” has been conceptualised, operationalised and measured in practice.\nOnce empirical data have been collected, a first step in their analysis is to explore and describe the recorded variables using appropriate descriptive statistics. It may be that our research question is a very simple one and the whole purpose of the research was to describe the distribution of a measured concept or phenomenon. In most cases, however, descriptive statistics are but the first – albeit essential – step in the analytic process. In real-life research scenarios, we are more interested in drawing comparisons between cases and identifying associations (relationships) between various concepts and phenomena. That will be the topic of workshop 3.\n\n\n(Access links through Canvas - Newcastle University login required)\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 1 | Getting Things in Proportion: Categorical Data and Percentages\nCHAPTER 2 | Summarizing and Communicating Numbers. Lots of Numbers (read until the section on Describing Relationships Between Variables)\nCHAPTER 3 | Why Are We Looking at Data Anyway? Populations and Measurement (recommended now, essential by Workshop 5)\n\nGoss-Sampson (2025) Statistical Analysis in JASP:\n\nUSING THE JASP ENVIRONMENT (pp. 2-7)\nDATA HANDLING IN JASP (pp. 8-10)\nJASP ANALYSIS MENU (pp. 12-15)\nDESCRIPTIVE STATISTICS (pp. 15-21)\nBASIC PLOTS (pp. 21-24)\n\n\nApplication:\n\nBekkers, René, and Bart Sandberg. 2019. “Grading Generalized Trust Across Europe”, Pp. 97-119 in: André, S., Kraaykamp, G., Meuleman, R. & Wittenberg, M. (Eds). Samenhang in Europa: eenheid in verscheidenheid. Proceedings zesde Nederlandse Workshop European Social Survey, The Hague, 16 March 2018.\n\n\n\n\nOn trust:\n\nDelhey, Jan, Kenneth Newton, and Christian Welzel. 2011. “How General Is Trust in ‘Most People’? Solving the Radius of Trust Problem.” American Sociological Review 76(5): 786–807.\nRobbins, Blaine G. 2022. “Measuring Generalized Trust: Two New Approaches.” Sociological Methods & Research 51(1): 305–56.\nRobbins, Blaine G. 2024. “An Empirical Comparison of Four Generalized Trust Scales: Test–Retest Reliability, Measurement Invariance, Predictive Validity, and Replicability.” Sociological Methods & Research 53(2): 760–803.\nUslaner, E. M. 2012. Chapter 7 (“Measuring generalized trust: in defense of the ‘standard’ question”, pp. 72-82) in Lyon, Fergus, Guido Möllering, and M. N. K. Saunders, eds. 2012. Handbook of Research Methods on Trust. Northampton, Mass: Edward Elgar Pub.\n\nStatistics:\n\nKranzler (2022) Statistics for the Terrified:\n\nSection II: Describing Univariate Data (pp. 42-83)\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 1 (“Data”)\nChapter 2 (“Study design”)\n\nStevens, S. S. 1946. “On the Theory of Scales of Measurement.” Science 103(2684): 677–80.\nDuncan, Otis Dudley. 1984. Notes on Social Measurement: Historical and Critical. New York: Russell Sage Foundation. (especially Chapter 4 discussing and criticising Stevens (1946))\n\n\n\n\n\n Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 1",
      "[W1] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w1.html#readings",
    "href": "Materials/Info/info_w1.html#readings",
    "title": "Measurement and Description",
    "section": "",
    "text": "Statistics:\n\nIMS: Chapters 1 (“Data”) and 2 (“Study design”)\n\nApplication:\n\nUslaner, E. M. 2012. Chapter 7 (“Measuring generalized trust: in defense of the ‘standard’ question”, pp. 72-82) in Lyon, Fergus, Guido Möllering, and M. N. K. Saunders, eds. 2012. Handbook of Research Methods on Trust. Northampton, Mass: Edward Elgar Pub.\nDelhey, Jan, Kenneth Newton, and Christian Welzel. 2011. “How General Is Trust in ‘Most People’? Solving the Radius of Trust Problem.” American Sociological Review 76(5): 786–807.\nBekkers, René, and Bart Sandberg. 2018. “Grading Generalized Trust Across Europe.” Paper presented at The 6th ESS Workshop in The Hague, 16th March 2018. Available at: https://osf.io/qntze\n\nAdvanced topics:\n\nRobbins, Blaine G. 2022. “Measuring Generalized Trust: Two New Approaches.” Sociological Methods & Research 51(1): 305–56.\nRobbins, Blaine G. 2024. “An Empirical Comparison of Four Generalized Trust Scales: Test–Retest Reliability, Measurement Invariance, Predictive Validity, and Replicability.” Sociological Methods & Research 53(2): 760–803.\n\nFurther reading:\n\nStevens, S. S. 1946. “On the Theory of Scales of Measurement.” Science 103(2684): 677–80.\nDuncan, Otis Dudley. 1984. Notes on Social Measurement: Historical and Critical. New York: Russell Sage Foundation. (especially Chapter 4 discussing and criticising Stevens (1946))",
    "crumbs": [
      "Materials",
      "Workshop 1",
      "[W1] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w1.html#lecture-slides",
    "href": "Materials/Info/info_w1.html#lecture-slides",
    "title": "Measurement and Description",
    "section": "",
    "text": "Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 1",
      "[W1] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w3.html",
    "href": "Materials/Info/info_w3.html",
    "title": "Modelling continuous outcomes",
    "section": "",
    "text": "Linear regression modelling is one of the most ubiquitous methods applied in the social sciences. It applies to cases where the phenomenon we aim to understand and describe (model) is ideally measured on a continuous numeric scale. This will be our “dependent” or “outcome” variable (our “explanandum”, the variable we want to explain). Regression modelling allows us to quantify the association between one or several explanatory (“independent”) variables and our outcome variable. This allows us to summarise associations and draw comparisons in our data more efficiently and to establish testable hypotheses about potential causal relationships. In the workshop we will scratch the surface of this versatile and foundational statistical method.\n\n\n(Access links through Canvas - Newcastle University login required)\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 5 | Modelling Relationships Using Regression\n\nGoss-Sampson (2025) Statistical Analysis in JASP:\n\nREGRESSION (pp. 75-88)\n\n\nApplication:\n\nChapter 4 (“Community life and social relations”, pp. 49-62) in Wilkinson and Pickett (2010) The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press.\nDelhey, Jan, and Kenneth Newton. 2005. “Predicting Cross-National Levels of Social Trust: Global Pattern or Nordic Exceptionalism?” European Sociological Review 21(4): 311–27.\nÖsterman, Marcus. 2021.“Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust.” Social Indicators Research 154(1): 211–33.\n\nPlus, the Electronic supplementary material: https://link.springer.com/article/10.1007/s11205-020-02529-y#Sec15\n\n\n\n\n\nStatistics:\n\nKranzler (2022) Statistics for the Terrified:\n\nChapter 11 (“Correlation Coefficients”)\nChapter 12 (“Linear regression”)\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 7 (“Linear regression with a single predictor”)\nChapter 8 (“Linear regression with multiple predictors”)\n\n\nAdvanced topics:\n\nClark, William Roberts, and Matt Golder. 2023. Interaction Models: Specification and Interpretation. Cambridge: Cambridge University Press.\n\n\n\n\n\n Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 3",
      "[W3] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w3.html#readings",
    "href": "Materials/Info/info_w3.html#readings",
    "title": "Modelling continuous outcomes",
    "section": "",
    "text": "Statistics:\n\nIMS: Chapter 7 (“Linear regression with a single predictor”) and Chapter 8 (“Linear regression with multiple predictors”)\n\nApplication:\n\nChapter 4 (“Community life and social relations”, pp. 49-62) in Wilkinson, Richard G., and Kate Pickett. 2010. The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press.\n\nLibrary link: https://libsearch.ncl.ac.uk/permalink/f/rm84mo/NCL_ALMA21184871930002411\nDownload the chapter in PDF: Pages from Wilkinson and Pickett (2010).pdf\n\nDelhey, Jan, and Kenneth Newton. 2005. “Predicting Cross-National Levels of Social Trust: Global Pattern or Nordic Exceptionalism?” European Sociological Review 21(4): 311–27.\n\nLibrary link: https://libsearch.ncl.ac.uk/permalink/f/15e3e4n/TN_cdi_proquest_miscellaneous_60098263\nDownload PDF: Delhey & Newton (2005) Predicting trust\n\nÖsterman, Marcus. 2021. “Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust.” Social Indicators Research 154(1): 211–33.\n\nLibrary link: https://libsearch.ncl.ac.uk/permalink/f/15e3e4n/TN_cdi_springer_journals_10_1007_s11205_020_02529_y\nDownload PDF: Osterman (2021)\nPlus, the Electronic supplementary material: https://link.springer.com/article/10.1007/s11205-020-02529-y#Sec15\n\n\nAdvanced topics:\n\nBrambor, T., W. R. Clark, and M. Golder. 2006. “Understanding Interaction Models: Improving Empirical Analyses.” Political Analysis 14(1): 63–82.\n\nLibrary link: https://ncl.alma.exlibrisgroup.com/leganto/public/44NEW_INST/citation/17130882680002411?auth=multiple.\n\nClark, William Roberts, and Matt Golder. 2023. Interaction Models: Specification and Interpretation. Cambridge: Cambridge University Press.\n\nLibrary link: https://ncl.alma.exlibrisgroup.com/leganto/public/44NEW_INST/citation/17130893350002411?auth=multiple.",
    "crumbs": [
      "Materials",
      "Workshop 3",
      "[W3] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w3.html#lecture-slides",
    "href": "Materials/Info/info_w3.html#lecture-slides",
    "title": "Modelling continuous outcomes",
    "section": "",
    "text": "Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 3",
      "[W3] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w5.html",
    "href": "Materials/Info/info_w5.html",
    "title": "Uncertainty and Inference",
    "section": "",
    "text": "To build up empirical intuition about data, comparisons, and the mechanics of regression modelling, in previous workshops we have focused on understanding the calculation and interpretation of regression coefficients. These ‘point estimates’ may appear as reliable and certain answers to concrete research (sub)questions, but in fact they are a well-intended guess mired in uncertainty. Can they really tell us something reliable about the phenomenon under study in our population of interest, beyond the sample of data that we used to calculate them? Here’s where it becomes essential to develop our understanding of statistical theory that we have so far avoided. Thinking carefully about probability, uncertainty and the challenges of drawing inferences beyond one’s available data will help better understand our – and other researchers’ – results and the claims that can be made on their back.\n\n\n(Access links through Canvas - Newcastle University login required)\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 3 | Why Are We Looking at Data Anyway? Populations and Measurement\nCHAPTER 7 | How Sure Can We Be About What Is Going On? Estimates and Intervals\nCHAPTER 9 | Putting Probability and Statistics Together\nCHAPTER 10 | Answering Questions and Claiming Discoveries\n\n\n\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data: (Access through Canvas - Newcastle University login required)\n\nCHAPTER 11 | Learning from Experience the Bayesian Way\nCHAPTER 12 | How Things Go Wrong\nCHAPTER 13 | How We Can Do Statistics Better\n\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 12 (“Confidence intervals with bootstrapping”)\nChapter 13 (“Inference with mathematical models”)\nChapter 24 (“Inference for linear regression with a single predictor”)\nChapter 25 (“Inference for linear regression with multiple predictors”)\nChapter 26 (“Inference for logistic regression”)\nChapters 16 – 22 (“Statistical Inference” section)\n\n\n\n\n\n Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 5",
      "[W5] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w5.html#readings",
    "href": "Materials/Info/info_w5.html#readings",
    "title": "Uncertainty and Inference",
    "section": "",
    "text": "Statistics:\n\nIMS:\n\nChapter 12 (“Confidence intervals with bootstrapping”)\nChapter 13 (“Inference with mathematical models”)\nChapter 24 (“Inference for linear regression with a single predictor”)\nChapter 25 (“Inference for linear regression with multiple predictors”)\nChapter 26 (“Inference for logistic regression”)\n\n\nFurther reading:\n\nIMS: Chapters 16 – 22 (“Statistical Inference” section)",
    "crumbs": [
      "Materials",
      "Workshop 5",
      "[W5] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w5.html#lecture-slides",
    "href": "Materials/Info/info_w5.html#lecture-slides",
    "title": "Uncertainty and Inference",
    "section": "",
    "text": "Download the slides",
    "crumbs": [
      "Materials",
      "Workshop 5",
      "[W5] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w2.html",
    "href": "Materials/Worksheets/draft_worksheet_w2.html",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "By the end of the session, you should be familiar with:\n\nhow to create and interpret cross-tabulations (contingency tables)\nhow to create some of the most commonly used plots to visually summarise relationships between two or more variables\nthe basic intuition behind “associations” among variables\n\n\n\n\nWe will continue where we left off in the last workshop, completing any exercises that remained unfinished. Then, using the same datasets that we downloaded in the last workshop (EVS7, ESS10), we tabulate or plot (as appropriate for the given data type) the relationship between the “social trust” variable and some other variables. We will then use a country-level dataset (available here) to reproduce the association between inequality and social trust presented in Figure 4.1 in Wilkinson and Pickett (2010).\n\n\n\nIn Workshop 1 you created a folder for this module on your institutional OneDrive storage drive (e.g. C:\\OneDrive - Newcastle University\\SOC2069) and within that a sub-folder called “Data”. You used that sub-folder to save the datasets downloaded as part of the exercises in the Workshop 1 Worksheet. If you haven’t go back to the Workshop 1 Worksheet and follow the guidance there to set up your folder structure for future use.\n\n\n\nIn Workshop 1 Worksheet - Exercise 3 we explored univariate distributions (i.e. single variables). As part of that exercise, you used country-specific data from the “World Values Survey, Wave 7”, which you downloaded directly from the WVS website. You may also have saved your work (and modified dataset) from Workshop 1 as a .jaspwith the name “wvs7-example.jasp” (or anything else that you found useful) as instructed in Workshop 1 Worksheet - Exercise 3 - Point 8. If so, you can open that file for this exercise and continue where you left off. Otherwise, follow the instructions in Workshop 1 Worksheet - Exercise 1 and 3 to download the WVS dataset (if needed) and load it into JASP.\nAs part of Workshop 1 Worksheet - Exercise 3 you have probably created a frequency table of the “social trust” variable. In this exercise, you will check how those frequencies are distributed across the levels of another categorical variables. For this purpose contingency tables are a useful tool.\n\nOpen the “WVS7” dataset. You should now see something like this:\n\n\n\n\n\n\n\nUsing the survey questionnaire, identify the following two variables in the dataset: “social trust” and “sex”. In the original dataset these should be named Q57 and Q260, respectively (however, you may have already renamed the “social trust” variable as part of last Workshop’s exercise). Using the Descriptives &gt; Descriptive Statistics menu option in JASP, create frequency tables for these two variables. You can request frequency tables for your variables in the Tables sub-option:\n\n\n\n\n\n\n\nQuestions\n\nWhat percentage of the respondents in your dataset had answered that “Most people can be trusted”?\nWhat is the percentage of female respondents in your dataset?\nWhat are the variables’ measurement level (Column type)? Is that correct?\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf the two variables were recorded as “Scale” in your dataset, then it is useful to change the column type (measurement level) to “Categorical”, which is the correct variable type for these two variables. We can do this by clicking on the Edit Data menu tab and scrolling horizontally to the variable of interest, then clicking on the data type icon next to the variable name and selecting the appropriate type for that variable; e.g.:\n\n\n\n\n\nOnce you change the variable type, you will notice that the value labels appear in the frequency tables instead of their numeric values, making it easier to understand.\nIf the variables were recognised as “Ordinal” by the software, then the labels are also identified and used in outputs, just like with “Nominal” variables.\n\n\n\nAs a next step, we are interested in finding out the distribution of social trust among men and women. For this, we will create a contingency table. Use the Frequencies &gt; [Classical] Contingency Tables menu option. Move the “social trust” variable to the Rows field and the “sex” variable to the Columns field.\nInterpret the Contingency Tables part of the output (you can hide the Chi-Squared Tests table from the output by un-ticking the \\(\\chi^2\\) option under the Statistics sub-menu). Expand the Cells sub-menu and experiment with the options.\n\n\nQuestions\n\nHow many women in your dataset answered “Need to be very careful”?\nWhat percentage of the men in your dataset answered that “Most people can be trusted”?\nWhat percentage of those who answered “Most people can be trusted” are men, and what percentage are women?\nBased on your cross-tabulation, do women or men in your dataset have a higher level of “social trust”\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe cross-tabulation should look something like this:\n\n\n\n\n\n\n791 women in this dataset answered “Need to be very careful?”\nTo get percentages, we need to tick the desired Cell options. If we are interested in the percentage of the row variable distribution within each of the column categories, we would request “Column” percentages:\n\nThis will look within the men category (i.e. Male adds up to 100%) and tell us that among them 48.67% stated that “Most people can be trusted”\nTo get the percentage of a column variable distribution within each of the row categories, we would request “Row” percentages instead, and find that among those who answered “Most people can be trusted” 44.89% are men and 55.11% are women in this dataset:\n\nTo sum up the cross-tabulation, we see that overall there are more women than men in this dataset, but men have a somewhat higher level of social trust (48.7% say that “Most people can be trusted” as opposed to 45.2% of the women)\n\n\nNow find a few other “Nominal” or “Ordinal” variables in the dataset and add them to the analysis. Repeat point 4 above with other combinations of variables. What happens if you add a third variable to Layers?\n\n\n\n\n\n\nFor this exercise and the next, we will use a different dataset: a dataset containing country-level (macro-) variables describing aggregate features of various societies. The dataset can be downloaded from this page, or through the link below (where you can also read a brief description of the dataset):\n\n\n\n\n\n\n Trust & Inequality: trust_inequality.dta – Download\n\n\n\n\n\nThis dataset combines data on “generalised/social trust” from the latest waves of the World Values Survey and the European Values Study with macro(country)-level data on World Development Indicators (WDI) provided by the World Bank. The main variables of interest taken from the WDI refer to measurements of economic inequality within countries. The dataset allows to replicate - using the latest available data - the analysis of the relationship between inequality and trust presented in Chapter 4 (“Community life and social relations”, pp. 49-62) of Wilkinson and Pickett (2010).\n\n\n\n\nDownload the dataset to your Data (sub)folder and open it in JASP\nCreate summary descriptive statistics for all the variables in the dataset (Descriptives &gt; Descriptive Statistics menu option).\n\n\n\n\n\n\n\nTip\n\n\n\nBecause there are only a few variables in the dataset, you can select them all by clicking one of them, then Ctrl + A, and moving them all over to the Variables box\n\n\nBecause we have quite a few variables to display, it’s better to transpose (rotate) the table so that the variable names are listed in the rows and the summary statistics in the columns. Tick the Transpose descriptives table box for this:\n\n\n\n\n\n\nCreate a new descriptive analysis in your JASP session (Descriptives &gt; Descriptive Statistics menu option). This will keep the summary statistics table you created earlier. In this new analysis, play around with the univariate descriptions that you are already familiar with and create a few frequency tables and plots for each variable. Make sure to chose the most appropriate tabulation/visualisation option for the given variable type\nNow let’s explore the relationship between “inequality” and “social trust” using a scatter plot.\n\n\nCreate another new descriptive analysis in your JASP session (Descriptives &gt; Descriptive Statistics menu option), to keep your univariate descriptives above intact on the output page.\nMove the two variables over to the Variables box. The variable measuring “social trust” at the country level is trust_pct (% of respondents in the given country who answered “Most people can be trusted” to the standard social trust question in the WVS/EVS), while the variable measuring “inequality” is inequality_s80s20 (a commonly employed measure of income inequality representing the ratio between the total net disposable income of the 20% of people having the highest income (S80) and the total net disposable income of the 20% of people having the lowest income (S20))\nExpand the Customizable plots option and tick Scatter plots\nPlay around with the options under Scatter plots to simplify the plot (e.g. remove the univariate distributions of the variables displayed on the margins/changed them to histograms, remove the regression line, etc.). You can also manually increase the size of the plot by dragging the bottom-right corner\n\n\nQuestions\n\nWhat is the scatter plot telling us? Note down everything that comes to your mind.\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe scatterplot would look something like this:\n\nWe see a somewhat negative, downward-tilting trend in the relationship between trust and inequality\n\n\n\nNow play around with the variables and check the association between some other Scale type variables in the dataset using scatterplots.\n\n\nQuestions\n\nWhat happens if you add the Region variable to the Split box?\nTry to interpret what this tri-variate plot is telling us\n\n\n\n\n\n\n\n\nSolutions\n\n\n\n\n\n\n\n\nThe tri-variate scatter-plot would look something like this:\n\n\n\n\n\nThe scatterplot is not very easy to read, but we get a sense that there is a negative, downward-tilting trend in the relationship between trust and inequality. We also see that countries in “Europe & Central Asia” tend to have lower values on the inequality scale and they are also more represented at the higher end of the social trust scale.\n\n\n\n\n\n\nCreate another new descriptive analysis in your JASP session (Descriptives &gt; Descriptive Statistics menu option), to keep your previous analysis above intact on the output page.\nWe will now check the distribution of “social trust” in different world regions using box plots. Move the trust_pct variable to the Variables box and the Region variable to the Split field. You can resize the output graph so that the Region labels are easier to see.\n\n\nQuestions\n\nWhat is the box plot telling us? Note down everything that comes to your mind. You can use the lecture slides to remind yourself of the information contained in box plots.\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe boxplot would look something like this:\n\nThe number of regions is a bit too high and the labels are long, so it’s not easy to get a good visual representation, but we see differences between Regions in their median level of social trust (the black horizontal line inside the box) and also find that some regions have higher variability than other Regions (the height of the boxes and the “whiskers”). Much of this variability,however, is also due to the number of countries within each region, with some regions having only a few countries within them.\n\n\n\n\n\nBuilding on the work you have done in Workshop 1 Worksheet - Exercise 4, open the dataset you have used to address one of the questions below.\n\nIdentify (the) two main variables relevant to the question, perform univariate descriptive statistics, and check their relationship using one of the plots/tabulations practised in the previous exercises above.\nSelect some other variables of different types and check their association with your main dependent variable using the plots/tabulations practised in the previous exercises above.\n\nReminder of the research questions to choose from to address in Assignment 1:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?\n\nFor now, choose one question that you find most sympathetic (you don’t need to stick with it for the assignment, but you could if you wanted to!). All of the questions can be answered with at least one of the survey datasets that you downloaded (the “WVS7” or “ESS10”) and often they both contain relevant variables."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w2.html#learning-outcomes",
    "href": "Materials/Worksheets/draft_worksheet_w2.html#learning-outcomes",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "By the end of the session, you should be familiar with:\n\nhow to create and interpret cross-tabulations (contingency tables)\nhow to create some of the most commonly used plots to visually summarise relationships between two or more variables\nthe basic intuition behind “associations” among variables"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w2.html#intro",
    "href": "Materials/Worksheets/draft_worksheet_w2.html#intro",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "We will continue where we left off in the last workshop, completing any exercises that remained unfinished. Then, using the same datasets that we downloaded in the last workshop (EVS7, ESS10), we tabulate or plot (as appropriate for the given data type) the relationship between the “social trust” variable and some other variables. We will then use a country-level dataset (available here) to reproduce the association between inequality and social trust presented in Figure 4.1 in Wilkinson and Pickett (2010)."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w2.html#exercise-0-your-module-data-and-analysis-folder",
    "href": "Materials/Worksheets/draft_worksheet_w2.html#exercise-0-your-module-data-and-analysis-folder",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "In Workshop 1 you created a folder for this module on your institutional OneDrive storage drive (e.g. C:\\OneDrive - Newcastle University\\SOC2069) and within that a sub-folder called “Data”. You used that sub-folder to save the datasets downloaded as part of the exercises in the Workshop 1 Worksheet. If you haven’t go back to the Workshop 1 Worksheet and follow the guidance there to set up your folder structure for future use."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w2.html#exercise-1-contingency-tables",
    "href": "Materials/Worksheets/draft_worksheet_w2.html#exercise-1-contingency-tables",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "In Workshop 1 Worksheet - Exercise 3 we explored univariate distributions (i.e. single variables). As part of that exercise, you used country-specific data from the “World Values Survey, Wave 7”, which you downloaded directly from the WVS website. You may also have saved your work (and modified dataset) from Workshop 1 as a .jaspwith the name “wvs7-example.jasp” (or anything else that you found useful) as instructed in Workshop 1 Worksheet - Exercise 3 - Point 8. If so, you can open that file for this exercise and continue where you left off. Otherwise, follow the instructions in Workshop 1 Worksheet - Exercise 1 and 3 to download the WVS dataset (if needed) and load it into JASP.\nAs part of Workshop 1 Worksheet - Exercise 3 you have probably created a frequency table of the “social trust” variable. In this exercise, you will check how those frequencies are distributed across the levels of another categorical variables. For this purpose contingency tables are a useful tool.\n\nOpen the “WVS7” dataset. You should now see something like this:\n\n\n\n\n\n\n\nUsing the survey questionnaire, identify the following two variables in the dataset: “social trust” and “sex”. In the original dataset these should be named Q57 and Q260, respectively (however, you may have already renamed the “social trust” variable as part of last Workshop’s exercise). Using the Descriptives &gt; Descriptive Statistics menu option in JASP, create frequency tables for these two variables. You can request frequency tables for your variables in the Tables sub-option:\n\n\n\n\n\n\n\nQuestions\n\nWhat percentage of the respondents in your dataset had answered that “Most people can be trusted”?\nWhat is the percentage of female respondents in your dataset?\nWhat are the variables’ measurement level (Column type)? Is that correct?\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf the two variables were recorded as “Scale” in your dataset, then it is useful to change the column type (measurement level) to “Categorical”, which is the correct variable type for these two variables. We can do this by clicking on the Edit Data menu tab and scrolling horizontally to the variable of interest, then clicking on the data type icon next to the variable name and selecting the appropriate type for that variable; e.g.:\n\n\n\n\n\nOnce you change the variable type, you will notice that the value labels appear in the frequency tables instead of their numeric values, making it easier to understand.\nIf the variables were recognised as “Ordinal” by the software, then the labels are also identified and used in outputs, just like with “Nominal” variables.\n\n\n\nAs a next step, we are interested in finding out the distribution of social trust among men and women. For this, we will create a contingency table. Use the Frequencies &gt; [Classical] Contingency Tables menu option. Move the “social trust” variable to the Rows field and the “sex” variable to the Columns field.\nInterpret the Contingency Tables part of the output (you can hide the Chi-Squared Tests table from the output by un-ticking the \\(\\chi^2\\) option under the Statistics sub-menu). Expand the Cells sub-menu and experiment with the options.\n\n\nQuestions\n\nHow many women in your dataset answered “Need to be very careful”?\nWhat percentage of the men in your dataset answered that “Most people can be trusted”?\nWhat percentage of those who answered “Most people can be trusted” are men, and what percentage are women?\nBased on your cross-tabulation, do women or men in your dataset have a higher level of “social trust”\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe cross-tabulation should look something like this:\n\n\n\n\n\n\n791 women in this dataset answered “Need to be very careful?”\nTo get percentages, we need to tick the desired Cell options. If we are interested in the percentage of the row variable distribution within each of the column categories, we would request “Column” percentages:\n\nThis will look within the men category (i.e. Male adds up to 100%) and tell us that among them 48.67% stated that “Most people can be trusted”\nTo get the percentage of a column variable distribution within each of the row categories, we would request “Row” percentages instead, and find that among those who answered “Most people can be trusted” 44.89% are men and 55.11% are women in this dataset:\n\nTo sum up the cross-tabulation, we see that overall there are more women than men in this dataset, but men have a somewhat higher level of social trust (48.7% say that “Most people can be trusted” as opposed to 45.2% of the women)\n\n\nNow find a few other “Nominal” or “Ordinal” variables in the dataset and add them to the analysis. Repeat point 4 above with other combinations of variables. What happens if you add a third variable to Layers?"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w2.html#exercise-2-scatterplots",
    "href": "Materials/Worksheets/draft_worksheet_w2.html#exercise-2-scatterplots",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "For this exercise and the next, we will use a different dataset: a dataset containing country-level (macro-) variables describing aggregate features of various societies. The dataset can be downloaded from this page, or through the link below (where you can also read a brief description of the dataset):\n\n\n\n\n\n\n Trust & Inequality: trust_inequality.dta – Download\n\n\n\n\n\nThis dataset combines data on “generalised/social trust” from the latest waves of the World Values Survey and the European Values Study with macro(country)-level data on World Development Indicators (WDI) provided by the World Bank. The main variables of interest taken from the WDI refer to measurements of economic inequality within countries. The dataset allows to replicate - using the latest available data - the analysis of the relationship between inequality and trust presented in Chapter 4 (“Community life and social relations”, pp. 49-62) of Wilkinson and Pickett (2010).\n\n\n\n\nDownload the dataset to your Data (sub)folder and open it in JASP\nCreate summary descriptive statistics for all the variables in the dataset (Descriptives &gt; Descriptive Statistics menu option).\n\n\n\n\n\n\n\nTip\n\n\n\nBecause there are only a few variables in the dataset, you can select them all by clicking one of them, then Ctrl + A, and moving them all over to the Variables box\n\n\nBecause we have quite a few variables to display, it’s better to transpose (rotate) the table so that the variable names are listed in the rows and the summary statistics in the columns. Tick the Transpose descriptives table box for this:\n\n\n\n\n\n\nCreate a new descriptive analysis in your JASP session (Descriptives &gt; Descriptive Statistics menu option). This will keep the summary statistics table you created earlier. In this new analysis, play around with the univariate descriptions that you are already familiar with and create a few frequency tables and plots for each variable. Make sure to chose the most appropriate tabulation/visualisation option for the given variable type\nNow let’s explore the relationship between “inequality” and “social trust” using a scatter plot.\n\n\nCreate another new descriptive analysis in your JASP session (Descriptives &gt; Descriptive Statistics menu option), to keep your univariate descriptives above intact on the output page.\nMove the two variables over to the Variables box. The variable measuring “social trust” at the country level is trust_pct (% of respondents in the given country who answered “Most people can be trusted” to the standard social trust question in the WVS/EVS), while the variable measuring “inequality” is inequality_s80s20 (a commonly employed measure of income inequality representing the ratio between the total net disposable income of the 20% of people having the highest income (S80) and the total net disposable income of the 20% of people having the lowest income (S20))\nExpand the Customizable plots option and tick Scatter plots\nPlay around with the options under Scatter plots to simplify the plot (e.g. remove the univariate distributions of the variables displayed on the margins/changed them to histograms, remove the regression line, etc.). You can also manually increase the size of the plot by dragging the bottom-right corner\n\n\nQuestions\n\nWhat is the scatter plot telling us? Note down everything that comes to your mind.\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe scatterplot would look something like this:\n\nWe see a somewhat negative, downward-tilting trend in the relationship between trust and inequality\n\n\n\nNow play around with the variables and check the association between some other Scale type variables in the dataset using scatterplots.\n\n\nQuestions\n\nWhat happens if you add the Region variable to the Split box?\nTry to interpret what this tri-variate plot is telling us\n\n\n\n\n\n\n\n\nSolutions\n\n\n\n\n\n\n\n\nThe tri-variate scatter-plot would look something like this:\n\n\n\n\n\nThe scatterplot is not very easy to read, but we get a sense that there is a negative, downward-tilting trend in the relationship between trust and inequality. We also see that countries in “Europe & Central Asia” tend to have lower values on the inequality scale and they are also more represented at the higher end of the social trust scale."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w2.html#exercise-3-box-plots",
    "href": "Materials/Worksheets/draft_worksheet_w2.html#exercise-3-box-plots",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "Create another new descriptive analysis in your JASP session (Descriptives &gt; Descriptive Statistics menu option), to keep your previous analysis above intact on the output page.\nWe will now check the distribution of “social trust” in different world regions using box plots. Move the trust_pct variable to the Variables box and the Region variable to the Split field. You can resize the output graph so that the Region labels are easier to see.\n\n\nQuestions\n\nWhat is the box plot telling us? Note down everything that comes to your mind. You can use the lecture slides to remind yourself of the information contained in box plots.\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nThe boxplot would look something like this:\n\nThe number of regions is a bit too high and the labels are long, so it’s not easy to get a good visual representation, but we see differences between Regions in their median level of social trust (the black horizontal line inside the box) and also find that some regions have higher variability than other Regions (the height of the boxes and the “whiskers”). Much of this variability,however, is also due to the number of countries within each region, with some regions having only a few countries within them."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w2.html#exercise-4-continue-your-analysis-for-assignment-1",
    "href": "Materials/Worksheets/draft_worksheet_w2.html#exercise-4-continue-your-analysis-for-assignment-1",
    "title": "Workshop 1 Worksheet",
    "section": "",
    "text": "Building on the work you have done in Workshop 1 Worksheet - Exercise 4, open the dataset you have used to address one of the questions below.\n\nIdentify (the) two main variables relevant to the question, perform univariate descriptive statistics, and check their relationship using one of the plots/tabulations practised in the previous exercises above.\nSelect some other variables of different types and check their association with your main dependent variable using the plots/tabulations practised in the previous exercises above.\n\nReminder of the research questions to choose from to address in Assignment 1:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?\n\nFor now, choose one question that you find most sympathetic (you don’t need to stick with it for the assignment, but you could if you wanted to!). All of the questions can be answered with at least one of the survey datasets that you downloaded (the “WVS7” or “ESS10”) and often they both contain relevant variables."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w4.html",
    "href": "Materials/Worksheets/draft_worksheet_w4.html",
    "title": "Workshop 4 Worksheet",
    "section": "",
    "text": "By the end of the session, you should be familiar with:\n\nrunning logistic regression in JASP\nthe interpretation of logistic regression coefficients\nsub-setting/filtering data in JASP\nrecoding/dichotomising a variable in JASP\n\n\n\n\nIn this worksheet we will practice another type of regression analysis, which allows us to model outcome/dependent/response/\\(y\\) variables that are not measured on a continuous numeric scale, but instead on a categorical measurement scale that allows only two values (e.g. “Yes”/“No”; “Agree”/“Disagree”; “Above average”/“Average and below”; “Trust”/“Doesn’t trust”; etc.). Such a variable is called binary, binomial (because it can take only two values) or dichotomous (because the two values present a “dichotomy”). Modelling such a variable using the linear regression approach from Workshop 3 would give inaccurate results, but we can generalise the logic of linear regression to make it applicable to dichotomous dependent variables. In fact, the method we learn about today - (binary/binomial) logistic regression - is the most foundational case of a broader category of statistical models called generalised linear models (GLMs). GLMs can be thought of as a two-stage modelling approach, in which we first model the response variable using a probability distribution - such as the binomial distribution in our case -, and then we model the parameter of the distribution using a collection of predictors and a special form of multiple regression. This all sounds very technical and it does involve some complex mathematics, but applying logistic regression in practice will feel very similar to what we have done with linear regression before. The challenge will be in finding a way to interpret the statistical results accurately and meaningfully given that the resulting regression coefficients refer to estimates on the mathematically transformed scale of the parameter of the distribution, rather than the original scale of measurement of the variables ass in the case of linear regression. The Advanced topics readings assigned for this week outline these challenges for those who would like to gain a deeper understanding of the mathematics and mechanics of logistic regression; for the rest of us, Connelly et al. (2016) (on the reading list) provides a very approachable introduction to the major challenges, specifically for sociological analyses (see, specifically, the sections between Parameter estimates in logistic regression models and The presentation of logistic regression results).\nIn essence, with binary logistic regression we will attempt to predict the probability that an observation falls into one of the two categories of a dichotomous dependent (outcome) variable based on one or more independent (predictor, explanatory) variables. Observations are predicted to fall into whichever one of the two outcome categories is most probable for them given the values they have on the independent variable(s). Logistic modelling is thus often considered a classification method rather than a regression method, especially in recent machine learning parlance.\n\n\n\n\n\n\nSolutions\n\n\n\nA JASP file with the solutions to the exercises can be downloaded from HERE.\n\n\n\n\n\n\n\n\nThis exercise is primarily designed to introduce some new data management skills that may be useful in other contexts, and to connect with the data and analysis performed in Workshop 3. In Workshop 3 Worksheet - Exercise 3 we fit a multiple linear regression model of “social trust” measured as a percentage of a country’s population who answered that “people in general can be trusted” (as opposed to “one cannot be too careful”) on the standard binary “social trust” survey question as asked in the World Values Survey (trust_pct). We regressed that outcome on two variables: inequality_s80s20 and Region.\nWhat if our research question would ask not about the distribution of trust on a percentage scale, but about the factors associated with whether the level of social trust in a country is above average?In this case, our “quantity of interest” is different and requires us to use a different dependent/outcome variable: one that dichotomises the proportion of trust_pct into two outcome categories: “below average” and “above average”. We can easily transform our existing measurement of social trust to map it onto such a binary dichotomy because the trust_pct measurement contains more detailed information. For this reason, in actual research it is not good practice to transform variables in such a way as to lose information; instead, we would strive to find a modelling method that applies to the format of the variable that encompasses the most available information. For our didactic purposes, however, we will dichotomise the trust_pct variable to practice this useful data-transformation technique.\nLet’s load the Trust & Inequality (trust_inequality.dta) dataset into JASP (which can be downloaded from https://cgmoreh.github.io/SOC2069-QUANT/Data/ if not yet downloaded to a local/OneDrive folder).\n\n\nIn JASP we can create new variables by switching to the Edit Data menu tab and clicking on the green plus sign above the first empty column at the end of our dataset (there are other ways too, but this is one):\n\n\n\n\n\nWhen clicked, a set of fields pop up where we can write in the name we want to give to the new variable (this is necessary) as well as other details. We will create a variable called trust_d to refer to “dyihotomised trust scale”. Once we enter the desired variable name into the Name field, we click enter and an empty variable is created. We can also add a label (Long name) and description, and for this exercise, under Computed type we will select to compute the values of the new variable “with R code”. This option is more flexible and allows us here to “cut” the trust_pct scale into two around the mean/average value.\nFor this, we need to know the mean value of trust_pct in the dataset. We can request a table of Descriptive Statistics for his, as we have done many times before, and find out that the mean value for trust_pct is 25.731. Returning to the dataset window, we enter the following R code into the Compute column definition field:\ncut(trust_pct, breaks = c(0, 25.731, 100))\nClicking the Compute column bar at the bottom of the field, the values are computed, and the window should look something like this:\n\n\n\n\n\nThe only thing we need to know about the R code we just entered is that “cut” the trust_pct variable into sections around three break-points: the value 0, the mean value (25.731) and the value 100. Because 0 and 100 represent the absolute theoretical extreme points of the trust_pct scale (because it’s a percentage scale), the only actual “cut” in the dataset is made around the mean value. In R, the c(...) function simply means that we are “combining” the values enumerated into a list of numbers; we need to use it if we want to specify more than one value. If we only specify a single “break” value in the cut(...) function, then the trust_pct scale will be cut into that many sections - and that’s not what we want here.\nWe still need to do some changes to this newly minted variable. We can click on the Label editor tab, and there we will see the current values assigned automatically based on our “cutting” procedure: the first category are trust_pct values between 0 and 25.7 (inclusive), and the second category codes trust_pct values between 25.7 and 100. We want some easier values and labels to use, so we’ll recode the first value as 0 and give it the label “Low trust”, and recode the second category as 1 and label it as “High trust”. Our window should now look something like this:\n\n\n\n\n\nWe can return to the Analyses menu tab now.\n\n\n\nWe can check how the newly created variable is distributed by the values of our “inequality” measure by creating a scatter plot of their co-variation/co-relation. We have done scatter plots many times now. The result - simplified a bit - would look like this:\n\n\n\n\n\nAs expected, the trust_d variable only takes values of 0 and 1. This variable will be our new dependent variable that we want to model as a function of “inequality” and “Region”, as we have done in Workshop 3 Worksheet - Exercise 3 with the trust_pct variable.\n\n\n\nAs a quick comparison with Workshop 3 Worksheet - Exercise 3, we can try to fit a linear regression using the new trust_d variable as dependent variable and inequality_s80s20 and Region as the independent/predictor variables. Set it up in JASP, and the resulting output tables should look like this:\n\n\n\n\n\n\nQuestions\n\nUsing the Answers to the Workshop 3 exercise sheet (you can find the sheet updated with answers on the website!), interpret the coefficients in the Coefficients table. Remember that the interpretation is exactly the same as in that previous exercise, because we have used a linear regression model. However, the scale of the dependent variable has changed, so that will effect the meaning of a one-unit difference in the dependent variable\n\n\n\n\n\nThe main shortcoming of the linear model we fit in the previous task is, of course, that because our dependent variable only has two values, the linear model does not make very accurate predictions of the expected values of trust_d, which it assumes to be a continuous numeric variable. It makes predictions of values in between 0 and 1, and most unfortunately, of values below 0 and above 1, which cannot empirically exist. It is also likely to violate one of the core assumptions of liner regression, that the “errors” (i.e. the values of the dependent variables conditional on the predictor variables; e.g. the differences between the dots and the regression line on the scatter plot in the case of only one predictor) are “normally distributed”.\nTo account for these issues, we should choose a modelling method that fits an s-shaped curve instead of a straight line. Doing so, we force the model to restrict its estimates to between 0 and 1. The logistic regression model is the tool for this, and fitting it in JASP is straightforward, even through the interpretation of the coefficients not so much.\nTo run a binary logistic regression, navigate to through the following menu tab options:\n\\[ \\text{Regression} \\longrightarrow \\text{[Classical] Logistic regression} \\]\n\n\n\n\n\nInside the Logistic regression settings, we select our dependent variable (which this time must have only two distinct values/categories!), our continuous numeric Covariate(s) and any categorically coded Factor(s). Once we do this, we get the results in the outputs window to the right. before we look at the results, let’s also tick the box for “Odds ratios” under Statistics &gt; Coefficients in the Logistic regression settings:\n\n\n\n\n\nThe resulting output should be:\n\n\n\n\n\nAs with multiple linear regression, our main interest lies in understanding the Coefficients table. Here, the coefficients for all the Regions compared to “Europe and Central Asia” (see the worked solution on Workshop 3 Worksheet - Exercise 3 for how to interpret the coefficients on the categorical predictor) are rather extreme; but they also seem to be rather unreliable by looking at the p column (which we will look at more closely and interpret in Week 6, so we’ll leave it for now). So let’s focus the interpretation on the coefficient for inequality_s80s20.\n\nQuestions\n\nWhat is the effect of a one-unit positive change on the inequality_s80s20 scale on the expected value of trust_d ?\nWhat is the effect of a one-unit positive change on the inequality_s80s20 scale on the odds of being a “high trust” country?\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nA JASP file with the solutions to the exercises can be downloaded from HERE.\n\n\nAs we know from the lecture and the statistics readings for this week, interpreting these numerical outputs form logistic regression models is very difficult, because the scale of our dependent variable (trust_d) has been log-transformed in the process of modelling. That means that the coefficients in the Estimate column can be interpreted along the same logic as with linear regression, but the expected difference/change in the dependent/outcome variable is measured on the logit (or log-odds) scale: the natural logarithm of the odds of being in the outcome category coded as 1 (i.e. “high trust”). So a one-unit difference in inequality_s80s20 is associated with a 4.530-unit increase in these log-odds values. That’s not very intuitive, and to make it easier to interpret, researchers often transform this log-odds scale to an Odds Ratio, which is perhaps more readily interpretable as a percentage change in the odds of being in the outcome category coded as 1 as opposed to being in the outcome category coded as 0.\nThe Odds Ratio may sound more intuitive, but it’s equally difficult to grasp. A better solution would be to transform the dependent variable scale further to plain “probabilities”, which we are intuitively more familiar with because its values are at equal distances and run between 0 and 1 (just like a proportion, and similar to a percentage scale).\nIn JASP we can request visual outputs for the effects of the independent variables on the probability of the outcome by ticking the Conditional estimates plots option under Inferential plots under Plots:\n\n\n\n\n\nThe resulting plots are visually more telling than the numbers in the regression output tables:\n\n\n\n\n\n\n\n\n\n\nWe find, for instance, that around the value of 7 on inequality_s80s20, the probability of being in the “High trust” category drops to under 0.25 (25%)\n\n\n\n\nLet’s look again at the assignment research questions. Some of these questions imply a dependent variable which is measured as a numeric scale or at least a long-ish (e.g. 7-point +) ordinal scale in one of the surveys we will use for the assignment (ESS10, WVS7, EVS2017). Other questions imply dependent variables that are more strictly categorical, and as such, we cannot model them using linear regression. For those, we may be able to apply a logistic regression model.\nIt may be the case that the categorical variable of choice has more than two categories. While there are specific modelling methods for those types of variables, we are not covering them on this module. Instead, in Week 6 we will practice some further data transformation techniques to easily dichotomise such multi-categorical/multinomial variables.\nIn this exercise, explore the assignment dataset using the Variable search function on the website to identify any available variables for answering one/some of the questions below, and check how the implied dependent variable was measured:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w4.html#learning-outcomes",
    "href": "Materials/Worksheets/draft_worksheet_w4.html#learning-outcomes",
    "title": "Workshop 4 Worksheet",
    "section": "",
    "text": "By the end of the session, you should be familiar with:\n\nrunning logistic regression in JASP\nthe interpretation of logistic regression coefficients\nsub-setting/filtering data in JASP\nrecoding/dichotomising a variable in JASP"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w4.html#intro",
    "href": "Materials/Worksheets/draft_worksheet_w4.html#intro",
    "title": "Workshop 4 Worksheet",
    "section": "",
    "text": "In this worksheet we will practice another type of regression analysis, which allows us to model outcome/dependent/response/\\(y\\) variables that are not measured on a continuous numeric scale, but instead on a categorical measurement scale that allows only two values (e.g. “Yes”/“No”; “Agree”/“Disagree”; “Above average”/“Average and below”; “Trust”/“Doesn’t trust”; etc.). Such a variable is called binary, binomial (because it can take only two values) or dichotomous (because the two values present a “dichotomy”). Modelling such a variable using the linear regression approach from Workshop 3 would give inaccurate results, but we can generalise the logic of linear regression to make it applicable to dichotomous dependent variables. In fact, the method we learn about today - (binary/binomial) logistic regression - is the most foundational case of a broader category of statistical models called generalised linear models (GLMs). GLMs can be thought of as a two-stage modelling approach, in which we first model the response variable using a probability distribution - such as the binomial distribution in our case -, and then we model the parameter of the distribution using a collection of predictors and a special form of multiple regression. This all sounds very technical and it does involve some complex mathematics, but applying logistic regression in practice will feel very similar to what we have done with linear regression before. The challenge will be in finding a way to interpret the statistical results accurately and meaningfully given that the resulting regression coefficients refer to estimates on the mathematically transformed scale of the parameter of the distribution, rather than the original scale of measurement of the variables ass in the case of linear regression. The Advanced topics readings assigned for this week outline these challenges for those who would like to gain a deeper understanding of the mathematics and mechanics of logistic regression; for the rest of us, Connelly et al. (2016) (on the reading list) provides a very approachable introduction to the major challenges, specifically for sociological analyses (see, specifically, the sections between Parameter estimates in logistic regression models and The presentation of logistic regression results).\nIn essence, with binary logistic regression we will attempt to predict the probability that an observation falls into one of the two categories of a dichotomous dependent (outcome) variable based on one or more independent (predictor, explanatory) variables. Observations are predicted to fall into whichever one of the two outcome categories is most probable for them given the values they have on the independent variable(s). Logistic modelling is thus often considered a classification method rather than a regression method, especially in recent machine learning parlance.\n\n\n\n\n\n\nSolutions\n\n\n\nA JASP file with the solutions to the exercises can be downloaded from HERE."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w4.html#exercise-5.1-predict-whether-social-trust-at-country-level-is-above-average",
    "href": "Materials/Worksheets/draft_worksheet_w4.html#exercise-5.1-predict-whether-social-trust-at-country-level-is-above-average",
    "title": "Workshop 4 Worksheet",
    "section": "",
    "text": "This exercise is primarily designed to introduce some new data management skills that may be useful in other contexts, and to connect with the data and analysis performed in Workshop 3. In Workshop 3 Worksheet - Exercise 3 we fit a multiple linear regression model of “social trust” measured as a percentage of a country’s population who answered that “people in general can be trusted” (as opposed to “one cannot be too careful”) on the standard binary “social trust” survey question as asked in the World Values Survey (trust_pct). We regressed that outcome on two variables: inequality_s80s20 and Region.\nWhat if our research question would ask not about the distribution of trust on a percentage scale, but about the factors associated with whether the level of social trust in a country is above average?In this case, our “quantity of interest” is different and requires us to use a different dependent/outcome variable: one that dichotomises the proportion of trust_pct into two outcome categories: “below average” and “above average”. We can easily transform our existing measurement of social trust to map it onto such a binary dichotomy because the trust_pct measurement contains more detailed information. For this reason, in actual research it is not good practice to transform variables in such a way as to lose information; instead, we would strive to find a modelling method that applies to the format of the variable that encompasses the most available information. For our didactic purposes, however, we will dichotomise the trust_pct variable to practice this useful data-transformation technique.\nLet’s load the Trust & Inequality (trust_inequality.dta) dataset into JASP (which can be downloaded from https://cgmoreh.github.io/SOC2069-QUANT/Data/ if not yet downloaded to a local/OneDrive folder).\n\n\nIn JASP we can create new variables by switching to the Edit Data menu tab and clicking on the green plus sign above the first empty column at the end of our dataset (there are other ways too, but this is one):\n\n\n\n\n\nWhen clicked, a set of fields pop up where we can write in the name we want to give to the new variable (this is necessary) as well as other details. We will create a variable called trust_d to refer to “dyihotomised trust scale”. Once we enter the desired variable name into the Name field, we click enter and an empty variable is created. We can also add a label (Long name) and description, and for this exercise, under Computed type we will select to compute the values of the new variable “with R code”. This option is more flexible and allows us here to “cut” the trust_pct scale into two around the mean/average value.\nFor this, we need to know the mean value of trust_pct in the dataset. We can request a table of Descriptive Statistics for his, as we have done many times before, and find out that the mean value for trust_pct is 25.731. Returning to the dataset window, we enter the following R code into the Compute column definition field:\ncut(trust_pct, breaks = c(0, 25.731, 100))\nClicking the Compute column bar at the bottom of the field, the values are computed, and the window should look something like this:\n\n\n\n\n\nThe only thing we need to know about the R code we just entered is that “cut” the trust_pct variable into sections around three break-points: the value 0, the mean value (25.731) and the value 100. Because 0 and 100 represent the absolute theoretical extreme points of the trust_pct scale (because it’s a percentage scale), the only actual “cut” in the dataset is made around the mean value. In R, the c(...) function simply means that we are “combining” the values enumerated into a list of numbers; we need to use it if we want to specify more than one value. If we only specify a single “break” value in the cut(...) function, then the trust_pct scale will be cut into that many sections - and that’s not what we want here.\nWe still need to do some changes to this newly minted variable. We can click on the Label editor tab, and there we will see the current values assigned automatically based on our “cutting” procedure: the first category are trust_pct values between 0 and 25.7 (inclusive), and the second category codes trust_pct values between 25.7 and 100. We want some easier values and labels to use, so we’ll recode the first value as 0 and give it the label “Low trust”, and recode the second category as 1 and label it as “High trust”. Our window should now look something like this:\n\n\n\n\n\nWe can return to the Analyses menu tab now.\n\n\n\nWe can check how the newly created variable is distributed by the values of our “inequality” measure by creating a scatter plot of their co-variation/co-relation. We have done scatter plots many times now. The result - simplified a bit - would look like this:\n\n\n\n\n\nAs expected, the trust_d variable only takes values of 0 and 1. This variable will be our new dependent variable that we want to model as a function of “inequality” and “Region”, as we have done in Workshop 3 Worksheet - Exercise 3 with the trust_pct variable.\n\n\n\nAs a quick comparison with Workshop 3 Worksheet - Exercise 3, we can try to fit a linear regression using the new trust_d variable as dependent variable and inequality_s80s20 and Region as the independent/predictor variables. Set it up in JASP, and the resulting output tables should look like this:\n\n\n\n\n\n\nQuestions\n\nUsing the Answers to the Workshop 3 exercise sheet (you can find the sheet updated with answers on the website!), interpret the coefficients in the Coefficients table. Remember that the interpretation is exactly the same as in that previous exercise, because we have used a linear regression model. However, the scale of the dependent variable has changed, so that will effect the meaning of a one-unit difference in the dependent variable\n\n\n\n\n\nThe main shortcoming of the linear model we fit in the previous task is, of course, that because our dependent variable only has two values, the linear model does not make very accurate predictions of the expected values of trust_d, which it assumes to be a continuous numeric variable. It makes predictions of values in between 0 and 1, and most unfortunately, of values below 0 and above 1, which cannot empirically exist. It is also likely to violate one of the core assumptions of liner regression, that the “errors” (i.e. the values of the dependent variables conditional on the predictor variables; e.g. the differences between the dots and the regression line on the scatter plot in the case of only one predictor) are “normally distributed”.\nTo account for these issues, we should choose a modelling method that fits an s-shaped curve instead of a straight line. Doing so, we force the model to restrict its estimates to between 0 and 1. The logistic regression model is the tool for this, and fitting it in JASP is straightforward, even through the interpretation of the coefficients not so much.\nTo run a binary logistic regression, navigate to through the following menu tab options:\n\\[ \\text{Regression} \\longrightarrow \\text{[Classical] Logistic regression} \\]\n\n\n\n\n\nInside the Logistic regression settings, we select our dependent variable (which this time must have only two distinct values/categories!), our continuous numeric Covariate(s) and any categorically coded Factor(s). Once we do this, we get the results in the outputs window to the right. before we look at the results, let’s also tick the box for “Odds ratios” under Statistics &gt; Coefficients in the Logistic regression settings:\n\n\n\n\n\nThe resulting output should be:\n\n\n\n\n\nAs with multiple linear regression, our main interest lies in understanding the Coefficients table. Here, the coefficients for all the Regions compared to “Europe and Central Asia” (see the worked solution on Workshop 3 Worksheet - Exercise 3 for how to interpret the coefficients on the categorical predictor) are rather extreme; but they also seem to be rather unreliable by looking at the p column (which we will look at more closely and interpret in Week 6, so we’ll leave it for now). So let’s focus the interpretation on the coefficient for inequality_s80s20.\n\nQuestions\n\nWhat is the effect of a one-unit positive change on the inequality_s80s20 scale on the expected value of trust_d ?\nWhat is the effect of a one-unit positive change on the inequality_s80s20 scale on the odds of being a “high trust” country?\n\n\n\n\n\n\n\n\nSolutions\n\n\n\nA JASP file with the solutions to the exercises can be downloaded from HERE.\n\n\nAs we know from the lecture and the statistics readings for this week, interpreting these numerical outputs form logistic regression models is very difficult, because the scale of our dependent variable (trust_d) has been log-transformed in the process of modelling. That means that the coefficients in the Estimate column can be interpreted along the same logic as with linear regression, but the expected difference/change in the dependent/outcome variable is measured on the logit (or log-odds) scale: the natural logarithm of the odds of being in the outcome category coded as 1 (i.e. “high trust”). So a one-unit difference in inequality_s80s20 is associated with a 4.530-unit increase in these log-odds values. That’s not very intuitive, and to make it easier to interpret, researchers often transform this log-odds scale to an Odds Ratio, which is perhaps more readily interpretable as a percentage change in the odds of being in the outcome category coded as 1 as opposed to being in the outcome category coded as 0.\nThe Odds Ratio may sound more intuitive, but it’s equally difficult to grasp. A better solution would be to transform the dependent variable scale further to plain “probabilities”, which we are intuitively more familiar with because its values are at equal distances and run between 0 and 1 (just like a proportion, and similar to a percentage scale).\nIn JASP we can request visual outputs for the effects of the independent variables on the probability of the outcome by ticking the Conditional estimates plots option under Inferential plots under Plots:\n\n\n\n\n\nThe resulting plots are visually more telling than the numbers in the regression output tables:\n\n\n\n\n\n\n\n\n\n\nWe find, for instance, that around the value of 7 on inequality_s80s20, the probability of being in the “High trust” category drops to under 0.25 (25%)"
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_w4.html#exercise-5.2-take-home-which-of-the-assignment-research-questions-could-be-addressed-using-a-logistic-regression-model",
    "href": "Materials/Worksheets/draft_worksheet_w4.html#exercise-5.2-take-home-which-of-the-assignment-research-questions-could-be-addressed-using-a-logistic-regression-model",
    "title": "Workshop 4 Worksheet",
    "section": "",
    "text": "Let’s look again at the assignment research questions. Some of these questions imply a dependent variable which is measured as a numeric scale or at least a long-ish (e.g. 7-point +) ordinal scale in one of the surveys we will use for the assignment (ESS10, WVS7, EVS2017). Other questions imply dependent variables that are more strictly categorical, and as such, we cannot model them using linear regression. For those, we may be able to apply a logistic regression model.\nIt may be the case that the categorical variable of choice has more than two categories. While there are specific modelling methods for those types of variables, we are not covering them on this module. Instead, in Week 6 we will practice some further data transformation techniques to easily dichotomise such multi-categorical/multinomial variables.\nIn this exercise, explore the assignment dataset using the Variable search function on the website to identify any available variables for answering one/some of the questions below, and check how the implied dependent variable was measured:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?"
  },
  {
    "objectID": "Materials/Info/jasp-software.html",
    "href": "Materials/Info/jasp-software.html",
    "title": "Statistical analysis software",
    "section": "",
    "text": "Statistical analysis software\nWe will be using the free and open-source software JASP for statistical analysis in the IT workshops and for the assignment. The software will be available in the workshop computer rooms, but you can also download it to your personal computers. JASP offers a very simple and intuitive interface for performing statistical analysis, but under the hood it operates on top of the powerful R statistical programming language.\nThe JASP website also provides various useful educational resources. for learning to use the software as well as basic statistical methods. Students new to JASP and/or statistics in general will find guidance on the Getting Started. and How to Use JASP. pages of the website, where the basic functionality of JASP as well as many different analyses are explained in detail. The site also provides brief videos for getting started with JASP, performing descriptive statistics or undertaking linear regression or logistic regression analyses, methods which we will cover on the module.\nThe module will focus on a very small number of statistical methods that are most useful for sociological data and research aims, so please follow the readings set out on the module Canvas page rather than rely on the statistical methods described in the JASP user manuals. Those are mostly useful for developing a generic understanding of the software interface and the menu options.\n\nData transformation in JASP\nBelow are some useful tutorial videos showcasing basic data transformation procedures in JASP:",
    "crumbs": [
      "Materials",
      "Software",
      "JASP <img src='/Materials/pics/JASP_logo.png' height='16' style='margin-top: -2px;'>"
    ]
  },
  {
    "objectID": "Materials/Info/introduction.html",
    "href": "Materials/Info/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to the module! This introductory lecture provides an overview of the quantitative methods component.\n\n\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data (Access through Canvas - Newcastle University login required)\n\nIntroduction\nCHAPTER 12 | How Things Go Wrong\nCHAPTER 13 | How We Can Do Statistics Better\n\n\n\n\n\nStatistics:\n\nKranzler (2022) Statistics for the Terrified:\n\nChapter 1: Effective Strategies for Studying Statistics\nChapter 2: Overcoming Math Anxiety\nChapter 3: Basic Math Concepts\n\n\nOn trust:\n\nLyon, Fergus, Guido Möllering, and M. N. K. Saunders, eds. 2012. Handbook of Research Methods on Trust. Northampton, Mass: Edward Elgar Pub.\n\nChapter 1: Introduction: the variety of methods for the multi-faceted phenomenon of trust (Fergus Lyon, Guido Möllering and Mark Saunders)\nChapter 5: Researching trust in different cultures (Friederike Welter and Nadezhda Alex)\nChapter 7: Measuring generalized trust: in defense of the ‘standard’ question (Eric Uslaner)\n\n\n\n\n\n\n Download the slides",
    "crumbs": [
      "Materials",
      "Introduction"
    ]
  },
  {
    "objectID": "Materials/Info/introduction.html#lecture-slides",
    "href": "Materials/Info/introduction.html#lecture-slides",
    "title": "Introduction",
    "section": "",
    "text": "Download the slides",
    "crumbs": [
      "Materials",
      "Introduction"
    ]
  },
  {
    "objectID": "Materials/Info/info_w5.html#essential-readings",
    "href": "Materials/Info/info_w5.html#essential-readings",
    "title": "Uncertainty and Inference",
    "section": "",
    "text": "(Access links through Canvas - Newcastle University login required)\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 3 | Why Are We Looking at Data Anyway? Populations and Measurement\nCHAPTER 7 | How Sure Can We Be About What Is Going On? Estimates and Intervals\nCHAPTER 9 | Putting Probability and Statistics Together\nCHAPTER 10 | Answering Questions and Claiming Discoveries",
    "crumbs": [
      "Materials",
      "Workshop 5",
      "[W5] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w5.html#further-readings",
    "href": "Materials/Info/info_w5.html#further-readings",
    "title": "Uncertainty and Inference",
    "section": "",
    "text": "Spiegelhalter (2020) The Art of Statistics: Learning from Data: (Access through Canvas - Newcastle University login required)\n\nCHAPTER 11 | Learning from Experience the Bayesian Way\nCHAPTER 12 | How Things Go Wrong\nCHAPTER 13 | How We Can Do Statistics Better\n\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 12 (“Confidence intervals with bootstrapping”)\nChapter 13 (“Inference with mathematical models”)\nChapter 24 (“Inference for linear regression with a single predictor”)\nChapter 25 (“Inference for linear regression with multiple predictors”)\nChapter 26 (“Inference for logistic regression”)\nChapters 16 – 22 (“Statistical Inference” section)",
    "crumbs": [
      "Materials",
      "Workshop 5",
      "[W5] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w3.html#essential-readings",
    "href": "Materials/Info/info_w3.html#essential-readings",
    "title": "Modelling continuous outcomes",
    "section": "",
    "text": "(Access links through Canvas - Newcastle University login required)\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 5 | Modelling Relationships Using Regression\n\nGoss-Sampson (2025) Statistical Analysis in JASP:\n\nREGRESSION (pp. 75-88)\n\n\nApplication:\n\nChapter 4 (“Community life and social relations”, pp. 49-62) in Wilkinson and Pickett (2010) The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press.\nDelhey, Jan, and Kenneth Newton. 2005. “Predicting Cross-National Levels of Social Trust: Global Pattern or Nordic Exceptionalism?” European Sociological Review 21(4): 311–27.\nÖsterman, Marcus. 2021.“Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust.” Social Indicators Research 154(1): 211–33.\n\nPlus, the Electronic supplementary material: https://link.springer.com/article/10.1007/s11205-020-02529-y#Sec15",
    "crumbs": [
      "Materials",
      "Workshop 3",
      "[W3] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w3.html#further-readings",
    "href": "Materials/Info/info_w3.html#further-readings",
    "title": "Modelling continuous outcomes",
    "section": "",
    "text": "Statistics:\n\nKranzler (2022) Statistics for the Terrified:\n\nChapter 11 (“Correlation Coefficients”)\nChapter 12 (“Linear regression”)\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 7 (“Linear regression with a single predictor”)\nChapter 8 (“Linear regression with multiple predictors”)\n\n\nAdvanced topics:\n\nClark, William Roberts, and Matt Golder. 2023. Interaction Models: Specification and Interpretation. Cambridge: Cambridge University Press.",
    "crumbs": [
      "Materials",
      "Workshop 3",
      "[W3] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w1.html#essential-readings",
    "href": "Materials/Info/info_w1.html#essential-readings",
    "title": "Measurement and Description",
    "section": "",
    "text": "(Access links through Canvas - Newcastle University login required)\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 1 | Getting Things in Proportion: Categorical Data and Percentages\nCHAPTER 2 | Summarizing and Communicating Numbers. Lots of Numbers (read until the section on Describing Relationships Between Variables)\nCHAPTER 3 | Why Are We Looking at Data Anyway? Populations and Measurement (recommended now, essential by Workshop 5)\n\nGoss-Sampson (2025) Statistical Analysis in JASP:\n\nUSING THE JASP ENVIRONMENT (pp. 2-7)\nDATA HANDLING IN JASP (pp. 8-10)\nJASP ANALYSIS MENU (pp. 12-15)\nDESCRIPTIVE STATISTICS (pp. 15-21)\nBASIC PLOTS (pp. 21-24)\n\n\nApplication:\n\nBekkers, René, and Bart Sandberg. 2019. “Grading Generalized Trust Across Europe”, Pp. 97-119 in: André, S., Kraaykamp, G., Meuleman, R. & Wittenberg, M. (Eds). Samenhang in Europa: eenheid in verscheidenheid. Proceedings zesde Nederlandse Workshop European Social Survey, The Hague, 16 March 2018.",
    "crumbs": [
      "Materials",
      "Workshop 1",
      "[W1] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w1.html#further-readings",
    "href": "Materials/Info/info_w1.html#further-readings",
    "title": "Measurement and Description",
    "section": "",
    "text": "On trust:\n\nDelhey, Jan, Kenneth Newton, and Christian Welzel. 2011. “How General Is Trust in ‘Most People’? Solving the Radius of Trust Problem.” American Sociological Review 76(5): 786–807.\nRobbins, Blaine G. 2022. “Measuring Generalized Trust: Two New Approaches.” Sociological Methods & Research 51(1): 305–56.\nRobbins, Blaine G. 2024. “An Empirical Comparison of Four Generalized Trust Scales: Test–Retest Reliability, Measurement Invariance, Predictive Validity, and Replicability.” Sociological Methods & Research 53(2): 760–803.\nUslaner, E. M. 2012. Chapter 7 (“Measuring generalized trust: in defense of the ‘standard’ question”, pp. 72-82) in Lyon, Fergus, Guido Möllering, and M. N. K. Saunders, eds. 2012. Handbook of Research Methods on Trust. Northampton, Mass: Edward Elgar Pub.\n\nStatistics:\n\nKranzler (2022) Statistics for the Terrified:\n\nSection II: Describing Univariate Data (pp. 42-83)\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 1 (“Data”)\nChapter 2 (“Study design”)\n\nStevens, S. S. 1946. “On the Theory of Scales of Measurement.” Science 103(2684): 677–80.\nDuncan, Otis Dudley. 1984. Notes on Social Measurement: Historical and Critical. New York: Russell Sage Foundation. (especially Chapter 4 discussing and criticising Stevens (1946))",
    "crumbs": [
      "Materials",
      "Workshop 1",
      "[W1] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w2.html#essential-readings",
    "href": "Materials/Info/info_w2.html#essential-readings",
    "title": "Comparisons and Associations",
    "section": "",
    "text": "(Access links through Canvas - Newcastle University login required)\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 2 | Summarizing and Communicating Numbers. Lots of Numbers (continue reading from the section on Describing Relationships Between Variables)\nCHAPTER 4 | What Causes What?\nCHAPTER 3 | Why Are We Looking at Data Anyway? Populations and Measurement (recommended now, essential by Workshop 5)\n\nGoss-Sampson (2025) Statistical Analysis in JASP:\n\nDESCRIPTIVE DATA VISUALISATION (pp. 21-30)\nEXPLORING DATA INTEGRITY (pp. 30-37)\nDATA TRANSFORMATION (pp. 38-41)\nCOMPARING TWO INDEPENDENT GROUPS (pp. 56-63)\nCOMPARING TWO RELATED GROUPS (pp. 63-69)\nCORRELATION ANALYSIS (pp. 69-75)\nCHI-SQUARE TEST FOR ASSOCIATION (pp. 145-152)\n\n\nApplication:\n\nChapter 4 (“Community life and social relations”, pp. 49-62) in Wilkinson and Pickett (2010) The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press.\nDelhey, Jan, and Kenneth Newton. 2005. “Predicting Cross-National Levels of Social Trust: Global Pattern or Nordic Exceptionalism?” European Sociological Review 21(4): 311–27.",
    "crumbs": [
      "Materials",
      "Workshop 2",
      "[W2] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w2.html#further-readings",
    "href": "Materials/Info/info_w2.html#further-readings",
    "title": "Comparisons and Associations",
    "section": "",
    "text": "Statistics:\n\nKranzler (2022) Statistics for the Terrified:\n\nChapter 9 (“The t Test”)\nChapter 10 (“Analysis of Variance”)\nChapter 11 (“Correlation Coefficients”)\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 4 (“Exploring categorical data”)\nChapter 5 (“Exploring numerical data”)\n\n\nSubstantive:\n\nDinesen, Peter Thisted, and René Bekkers. 2017. “The Foundations of Individuals’ Generalized Social Trust: A Review.” Pp. 77–100 in Trust in Social Dilemmas, edited by P. A. M. van Lange, B. Rockenbach, and T. Yamagishi. New York, NY: Oxford University Press.",
    "crumbs": [
      "Materials",
      "Workshop 2",
      "[W2] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w4.html#essential-readings",
    "href": "Materials/Info/info_w4.html#essential-readings",
    "title": "Modelling dichotomous outcomes",
    "section": "",
    "text": "(Access links through Canvas - Newcastle University login required)\n\nSpiegelhalter (2020) The Art of Statistics: Learning from Data:\n\nCHAPTER 5 | Modelling Relationships Using Regression (reading from section Different Types of Response Variable)\nCHAPTER 6 | Algorithms, Analytics and Prediction\nCHAPTER 8 | Probability – the Language of Uncertainty and Variability\n\nGoss-Sampson (2025) Statistical Analysis in JASP:\n\nLOGISTIC REGRESSION (pp. 88-92)\n\n\nApplication:\n\nDelhey, Jan, and Kenneth Newton (2003) “Who Trusts?: The Origins of Social Trust in Seven Societies.” European Societies 5(2): 93–137.",
    "crumbs": [
      "Materials",
      "Workshop 4",
      "[W4] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/info_w4.html#further-readings",
    "href": "Materials/Info/info_w4.html#further-readings",
    "title": "Modelling dichotomous outcomes",
    "section": "",
    "text": "Statistics:\n\nÇetinkaya-Rundel & Hardin (2024) Introduction to Modern Statistics:\n\nChapter 9 (“Logistic regression”)\n\nConnelly, Roxanne, Vernon Gayle, and Paul S. Lambert (2016) “Statistical Modelling of Key Variables in Social Survey Data Analysis”. Methodological Innovations9:205979911663800.\n\nAdvanced topics:\n\nMood, Carina (2010) “Logistic Regression: Why We Cannot Do What We Think We Can Do, and What We Can Do About It.” European Sociological Review 26(1): 67–82.\nBreen, Richard, Kristian Bernt Karlson, and Anders Holm (2018) “Interpreting and Understanding Logits, Probits, and Other Nonlinear Probability Models.” Annual Review of Sociology 44(1): 39–54.",
    "crumbs": [
      "Materials",
      "Workshop 4",
      "[W4] Info and Slides"
    ]
  },
  {
    "objectID": "Materials/Info/introduction.html#essential-readings",
    "href": "Materials/Info/introduction.html#essential-readings",
    "title": "Introduction",
    "section": "",
    "text": "Spiegelhalter (2020) The Art of Statistics: Learning from Data (Access through Canvas - Newcastle University login required)\n\nIntroduction\nCHAPTER 12 | How Things Go Wrong\nCHAPTER 13 | How We Can Do Statistics Better",
    "crumbs": [
      "Materials",
      "Introduction"
    ]
  },
  {
    "objectID": "Materials/Info/introduction.html#further-readings",
    "href": "Materials/Info/introduction.html#further-readings",
    "title": "Introduction",
    "section": "",
    "text": "Statistics:\n\nKranzler (2022) Statistics for the Terrified:\n\nChapter 1: Effective Strategies for Studying Statistics\nChapter 2: Overcoming Math Anxiety\nChapter 3: Basic Math Concepts\n\n\nOn trust:\n\nLyon, Fergus, Guido Möllering, and M. N. K. Saunders, eds. 2012. Handbook of Research Methods on Trust. Northampton, Mass: Edward Elgar Pub.\n\nChapter 1: Introduction: the variety of methods for the multi-faceted phenomenon of trust (Fergus Lyon, Guido Möllering and Mark Saunders)\nChapter 5: Researching trust in different cultures (Friederike Welter and Nadezhda Alex)\nChapter 7: Measuring generalized trust: in defense of the ‘standard’ question (Eric Uslaner)",
    "crumbs": [
      "Materials",
      "Introduction"
    ]
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_introduction.html",
    "href": "Materials/Worksheets/draft_worksheet_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Throughout this short course, we will be using the measurement and estimation of “social trust” as a guiding example. However, the aim is to help you build up your skills and confidence in asking and addressing research questions of your own, and the assessment questions will ask you to analyse some other chosen research topic.\n\n\nBelow are some research questions that you can choose from to address in Assignment 1:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?\n\nFor now, choose one question that you find most sympathetic (you don’t need to stick with it for the assignment, but you could if you wanted to!). All of the questions can be answered with at least one of the survey datasets that you downloaded (the “WVS7” or “ESS10”) and often they both contain relevant variables.\n\nIdentify your “explanandum” - i.e. the core phenomenon/concept/behaviour/etc. that the research question aims to explain. The questions all postulate a relationship/association between two or more variables (the topic of the next workshop), but for now, think carefully about the question and how it is formulated, and identify which is the variable that will be the target of explanation, and which variable (if mentioned) will be used for explaining it. For example, in the research question “Does education increase social trust?”, the variable we are interested in explaining is “social trust”, while “education” is the variable that we will use to explain it. In later workshops we will develop better vocabulary to describe associations between variables.\nOnce the core phenomenon to be explained is identified, look through the two survey questionnaires to identify any variables that might exist in the dataset that captures it. This may require some trial-and-error with testing out search words.\nOnce you have found one (or several) candidate variable(s), navigate to the relevant survey website and select a single country for which to download data. You will be working with single-country datasets for your assignment. Download the dataset, import it into JASP, find the relevant variable and perform some descriptive analysis on the chosen variable as you have done in the previous exercise.\nMake sure to add your noted and interpretations on the analysis results and save your analysis for later. You could create a new sub-folder for your “Assignment 1” work and save your analysis there for future use. If you end up liking your chosen question, you can continue this analysis in the next workshop."
  },
  {
    "objectID": "Materials/Worksheets/draft_worksheet_introduction.html#exercise-4-begin-your-analysis-for-assignment-1",
    "href": "Materials/Worksheets/draft_worksheet_introduction.html#exercise-4-begin-your-analysis-for-assignment-1",
    "title": "Introduction",
    "section": "",
    "text": "Below are some research questions that you can choose from to address in Assignment 1:\n\nAre religious people more satisfied with life?\nAre older people more likely to see the death penalty as justifiable?\nWhat factors are associated with opinions about future European Union enlargement among Europeans?\nIs higher internet use associated with stronger anti-immigrant sentiments?\nHow does victimisation relate to trust in the police?\nWhat factors are associated with belief in life after death?\nAre government/public sector employees more inclined to perceive higher levels of corruption than those working in the private sector?\n\nFor now, choose one question that you find most sympathetic (you don’t need to stick with it for the assignment, but you could if you wanted to!). All of the questions can be answered with at least one of the survey datasets that you downloaded (the “WVS7” or “ESS10”) and often they both contain relevant variables.\n\nIdentify your “explanandum” - i.e. the core phenomenon/concept/behaviour/etc. that the research question aims to explain. The questions all postulate a relationship/association between two or more variables (the topic of the next workshop), but for now, think carefully about the question and how it is formulated, and identify which is the variable that will be the target of explanation, and which variable (if mentioned) will be used for explaining it. For example, in the research question “Does education increase social trust?”, the variable we are interested in explaining is “social trust”, while “education” is the variable that we will use to explain it. In later workshops we will develop better vocabulary to describe associations between variables.\nOnce the core phenomenon to be explained is identified, look through the two survey questionnaires to identify any variables that might exist in the dataset that captures it. This may require some trial-and-error with testing out search words.\nOnce you have found one (or several) candidate variable(s), navigate to the relevant survey website and select a single country for which to download data. You will be working with single-country datasets for your assignment. Download the dataset, import it into JASP, find the relevant variable and perform some descriptive analysis on the chosen variable as you have done in the previous exercise.\nMake sure to add your noted and interpretations on the analysis results and save your analysis for later. You could create a new sub-folder for your “Assignment 1” work and save your analysis there for future use. If you end up liking your chosen question, you can continue this analysis in the next workshop."
  }
]